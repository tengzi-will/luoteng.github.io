<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="code,tensorflow,">










<meta name="description" content="基础创建常量1234# 创建一个(1,2)维常量m1 = tf.constant([[3,3]])# 创建一个(2,1)常量m2 = tf.constant([[2],[3]]) 定义变量12# 定义一个(2,)形状的变量x = tf.Variable([1,2]) 运算基本运算123456# 矩阵乘法op，m1，m2为可相乘的张量，product为结果张量product = tf.matmul(">
<meta name="keywords" content="code,tensorflow">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensorflow 学习笔记">
<meta property="og:url" content="http://yoursite.com/2019/03/09/Tensorflow-学习笔记/index.html">
<meta property="og:site_name" content="LuoTeng&#39;s Blog">
<meta property="og:description" content="基础创建常量1234# 创建一个(1,2)维常量m1 = tf.constant([[3,3]])# 创建一个(2,1)常量m2 = tf.constant([[2],[3]]) 定义变量12# 定义一个(2,)形状的变量x = tf.Variable([1,2]) 运算基本运算123456# 矩阵乘法op，m1，m2为可相乘的张量，product为结果张量product = tf.matmul(">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://i.loli.net/2019/03/10/5c84633139439.png">
<meta property="og:image" content="https://i.loli.net/2019/03/14/5c8a36879b6d5.png">
<meta property="og:image" content="https://i.loli.net/2019/03/14/5c8a396eac8d3.png">
<meta property="og:image" content="https://i.loli.net/2019/03/14/5c8a409fa81bb.png">
<meta property="og:image" content="https://i.loli.net/2019/03/14/5c8a4346cfbed.png">
<meta property="og:image" content="https://i.loli.net/2019/03/14/5c8a4a1526dec.png">
<meta property="og:image" content="https://i.loli.net/2019/03/14/5c8a4df832c2f.png">
<meta property="og:image" content="https://i.loli.net/2019/03/14/5c8a51a78f743.png">
<meta property="og:image" content="https://i.loli.net/2019/03/14/5c8a565a649ff.png">
<meta property="og:image" content="https://i.loli.net/2019/03/14/5c8a565ef0599.png">
<meta property="og:image" content="https://i.loli.net/2019/03/14/5c8a583573050.png">
<meta property="og:updated_time" content="2019-03-18T13:05:04.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Tensorflow 学习笔记">
<meta name="twitter:description" content="基础创建常量1234# 创建一个(1,2)维常量m1 = tf.constant([[3,3]])# 创建一个(2,1)常量m2 = tf.constant([[2],[3]]) 定义变量12# 定义一个(2,)形状的变量x = tf.Variable([1,2]) 运算基本运算123456# 矩阵乘法op，m1，m2为可相乘的张量，product为结果张量product = tf.matmul(">
<meta name="twitter:image" content="https://i.loli.net/2019/03/10/5c84633139439.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/03/09/Tensorflow-学习笔记/">





  <title>Tensorflow 学习笔记 | LuoTeng's Blog</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">LuoTeng's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">每一个不曾起舞的日子都是对生命的辜负</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/09/Tensorflow-学习笔记/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Luo Teng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LuoTeng's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Tensorflow 学习笔记</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-09T17:12:43+08:00">
                2019-03-09
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/工具/" itemprop="url" rel="index">
                    <span itemprop="name">工具</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/工具/tensorflow/" itemprop="url" rel="index">
                    <span itemprop="name">tensorflow</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><h3 id="创建常量"><a href="#创建常量" class="headerlink" title="创建常量"></a>创建常量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个(1,2)维常量</span></span><br><span class="line">m1 = tf.constant([[<span class="number">3</span>,<span class="number">3</span>]])</span><br><span class="line"><span class="comment"># 创建一个(2,1)常量</span></span><br><span class="line">m2 = tf.constant([[<span class="number">2</span>],[<span class="number">3</span>]])</span><br></pre></td></tr></table></figure>
<h3 id="定义变量"><a href="#定义变量" class="headerlink" title="定义变量"></a>定义变量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一个(2,)形状的变量</span></span><br><span class="line">x = tf.Variable([<span class="number">1</span>,<span class="number">2</span>])</span><br></pre></td></tr></table></figure>
<h3 id="运算"><a href="#运算" class="headerlink" title="运算"></a>运算</h3><h4 id="基本运算"><a href="#基本运算" class="headerlink" title="基本运算"></a>基本运算</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 矩阵乘法op，m1，m2为可相乘的张量，product为结果张量</span></span><br><span class="line">product = tf.matmul(m1, m2)</span><br><span class="line"><span class="comment"># 矩阵加法op，x+y，add为结果张量，x和y的张量维度要一致</span></span><br><span class="line">add = tf.add(x, y)</span><br><span class="line"><span class="comment"># 矩阵减法op，x-y，sub为结果张量，x和y的张量维度要一致</span></span><br><span class="line">sub = tf.subtract(x, y)</span><br></pre></td></tr></table></figure>
<h4 id="逻辑运算"><a href="#逻辑运算" class="headerlink" title="逻辑运算"></a>逻辑运算</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回input在axis所在维度上的最大值坐标</span></span><br><span class="line">tf.argmax(input_tensor, axis=<span class="keyword">None</span>)</span><br><span class="line"><span class="comment"># 判断x和y的值是否相等，返回一个bool类型的张量</span></span><br><span class="line">tf.equal(x, y)</span><br><span class="line"><span class="comment"># 将张量x的元素类型转化为dtype型</span></span><br><span class="line">tf.cast(x, dtype)</span><br><span class="line"><span class="comment"># 计算input_tensor在axis维度上的均值，若axis默认为None，计算所有维度</span></span><br><span class="line">tf.reduce_mean(input_tensor, axis=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<h3 id="所有变量初始化"><a href="#所有变量初始化" class="headerlink" title="所有变量初始化"></a>所有变量初始化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在会话中必须要执行的第一步</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure>
<h3 id="创建会话"><a href="#创建会话" class="headerlink" title="创建会话"></a>创建会话</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 第一种方式</span></span><br><span class="line">sess = tf.Session() <span class="comment"># 定义会话</span></span><br><span class="line">result = sess.run(product) <span class="comment"># 调用sess中的run方法来执行矩阵乘法op</span></span><br><span class="line">print(result) <span class="comment"># 打印结果</span></span><br><span class="line">sess.close() <span class="comment"># 结束回话</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 第二种方式</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    result = sess.run(product) <span class="comment"># 调用sess中的run方法来执行矩阵乘法op</span></span><br><span class="line">    print(result)</span><br></pre></td></tr></table></figure>
<h3 id="Fetch-amp-Feed"><a href="#Fetch-amp-Feed" class="headerlink" title="Fetch &amp; Feed"></a>Fetch &amp; Feed</h3><p><strong>Fetch:</strong> 可以在session中同时计算多个tensor或执行多个操作<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义三个常量</span></span><br><span class="line">input1 = tf.constant(<span class="number">3.0</span>)</span><br><span class="line">input2 = tf.constant(<span class="number">2.0</span>)</span><br><span class="line">input3 = tf.constant(<span class="number">5.0</span>)</span><br><span class="line"><span class="comment"># 加法op</span></span><br><span class="line">add = tf.add(input2,input3)</span><br><span class="line"><span class="comment"># 乘法op</span></span><br><span class="line">mul = tf.multiply(input1, add)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    result1, result2 = sess.run([mul, add])</span><br><span class="line">    print(result1,result2)</span><br></pre></td></tr></table></figure></p>
<p><strong>Feed:</strong> 先定义占位符，等需要的时候再传入数据<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义两个tensor，不传入数据</span></span><br><span class="line">input1 = tf.placeholder(tf.float32)</span><br><span class="line">input2 = tf.placeholder(tf.float32)</span><br><span class="line"><span class="comment"># 乘法op</span></span><br><span class="line">output = tf.multiply(input1, input2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(output, feed_dict=&#123;input1:<span class="number">8.0</span>,input2:<span class="number">2.0</span>&#125;))</span><br></pre></td></tr></table></figure></p>
<h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><h3 id="变量初始化器"><a href="#变量初始化器" class="headerlink" title="变量初始化器"></a>变量初始化器</h3><p>随机数生成函数</p>
<ul>
<li>tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32)</li>
<li>tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32)</li>
<li>tf.random_uniform(shape, minval=0, maxval=None, dtype=tf.float32)</li>
<li>tf.random_gamma(shape, alpha, beta=None, dtype=tf.float32)<br>与 tf.Variable() 配合使用</li>
</ul>
<p>变量初始化函数</p>
<ul>
<li>tf.constant_initializer(value=0, dtype=tf.float32)</li>
<li>tf.random_normal_initializer(mean=0.0, stddev=1.0, dtype=tf.float32)</li>
<li>tf.truncated_normal_initializer(mean=0.0, stddev=1.0, dtype=tf.float32)</li>
<li>tf.random_uniform_initializer(minval=0, maxval=None, dtype=tf.float32)</li>
<li>tf.ones_initializer()</li>
<li>tf.zeros_initializer()<br>与 tf.get_variable() 配合使用</li>
</ul>
<p>常数生成函数</p>
<ul>
<li>tf.ones(shape, dtype=tf.float32)</li>
<li>tf.zeros(shape, dtype=tf.float32)</li>
<li>tf.fill(dims, value)</li>
<li>tf.constant(value, dtype=None, shape=None)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成全1张量，shape为张量形状</span></span><br><span class="line">tf.ones(shape)</span><br><span class="line"><span class="comment"># 生成全0张量，shape为张量形状</span></span><br><span class="line">tf.zeros(shape)</span><br><span class="line"><span class="comment"># 生成随机正态分布，shape为张量形状</span></span><br><span class="line">initial = tf.random_normal(shape)</span><br><span class="line"><span class="comment"># 生成一个截断的正态分布，shape为张量形状</span></span><br><span class="line">initial = tf.truncated_normal(shape, stddev=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<p>以函数的形式定义变量的初始化<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape)</span>:</span></span><br><span class="line">    initial = tf.truncated_normal(shape, stddev=<span class="number">0.1</span>) <span class="comment"># 生成一个截断的正态分布</span></span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial)</span><br></pre></td></tr></table></figure></p>
<h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><p><img src="https://i.loli.net/2019/03/10/5c84633139439.png" alt="01_activation"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tensor为需要激活的神经元</span></span><br><span class="line">tanh = tf.nn.tanh(tensor)</span><br><span class="line">relu = tf.nn.relu(tensor)</span><br></pre></td></tr></table></figure>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 二次代价函数，y_actual为真实值，y_predict为预测值</span></span><br><span class="line">loss = tf.losses.mean_squared_error(y_actual, y_predict)</span><br><span class="line"><span class="comment"># 交叉熵</span></span><br><span class="line">loss = tf.losses.sigmoid_cross_entropy(y_actual, y_predict) <span class="comment"># 用于激活函数sigmoid的结果</span></span><br><span class="line">loss = tf.losses.softmax_cross_entropy(y_actual, y_predict) <span class="comment"># 用于softmax的结果</span></span><br></pre></td></tr></table></figure>
<h3 id="防止过拟合"><a href="#防止过拟合" class="headerlink" title="防止过拟合"></a>防止过拟合</h3><h4 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义L1层神经元按比例失活，失活比例为keep_prob</span></span><br><span class="line">L1_drop = tf.nn.dropout(L1, keep_prob)</span><br></pre></td></tr></table></figure>
<p>keep_prob建议使用占位符方式传入</p>
<h4 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># L1正则项损失</span></span><br><span class="line">l1_loss = tf.nn.l1_loss(W) + tf.nn.l1_loss(b)</span><br><span class="line"><span class="comment"># L2正则项损失</span></span><br><span class="line">l2_loss = tf.nn.l2_loss(W) + tf.nn.l2_loss(b)</span><br><span class="line"><span class="comment"># 将正则化损失加入loss，0.0005为正则化参数</span></span><br><span class="line">loss = tf.losses.softmax_cross_entropy(y,prediction) + <span class="number">0.0005</span>*l2_loss</span><br></pre></td></tr></table></figure>
<p>由于偏置项b较权重W而言，参数少很多，在计算正则化时可以不予考虑</p>
<h3 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h3><p>优化器列表</p>
<ul>
<li>tf.train.GradientDescentOptimizer</li>
<li>tf.train.AdadeltaOptimizer</li>
<li>tf.train.AdagradOptimizer</li>
<li>tf.train.AdagradDAOptimizer</li>
<li>tf.train.MomentumOptimizer</li>
<li>tf.train.FtrlOptimizer</li>
<li>tf.train.ProximalGradientDescentOptimizer</li>
<li>tf.train.ProximalAdagradOptimizer</li>
<li>tf.train.RMSPropOptimizer</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一个梯度下降法优化器，η为学习率，一般取值0.01</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(η)</span><br><span class="line"><span class="comment"># 定义Adam优化器，η为学习率，一般取值0.001</span></span><br><span class="line">optimizer = tf.train.AdamOptimizer(η)</span><br><span class="line"><span class="comment"># 最小化代价函数</span></span><br><span class="line">train = optimizer.minimize(loss)</span><br></pre></td></tr></table></figure>
<p>一般情况下Adam优化器比梯度下降优化器的学习率取值小，Adam优化器也是一个整体性能较优的优化器，如果不知道如何选择优化器，可以首先考虑Adam</p>
<h4 id="其他优化器"><a href="#其他优化器" class="headerlink" title="其他优化器"></a>其他优化器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">optimizer = tf.train.GradientDescentOptimizer(η)</span><br><span class="line">optimizer = tf.train.AdamOptimizer(η)</span><br></pre></td></tr></table></figure>
<h2 id="图片预处理"><a href="#图片预处理" class="headerlink" title="图片预处理"></a>图片预处理</h2><h3 id="图像解码"><a href="#图像解码" class="headerlink" title="图像解码"></a>图像解码</h3><p>在图片预处理之前，需要将图片读取为张量的形式<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取图片，其中filename为图片完整路径</span></span><br><span class="line">image = tf.read_file(filename)</span><br><span class="line"><span class="comment"># 效果同上</span></span><br><span class="line">image = tf.gfile.FastGFile(filename, <span class="string">'rb'</span>).read()</span><br><span class="line"><span class="comment"># 将图像解码，或者tf.image.decode_png</span></span><br><span class="line">image = tf.image.decode_jpeg(image, channels=<span class="number">3</span>)</span><br></pre></td></tr></table></figure></p>
<p>注：解码函数根据图像格式的选取有所不同</p>
<p>读取图片为张量后，将其数值进行调整<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将 0~255 的像素转化为 0.0~1.0 范围内的实数</span></span><br><span class="line">image = tf.image.convert_image_dtype(image, dtype=tf.float32)</span><br><span class="line"><span class="comment"># 下述三步骤同上述步骤效果</span></span><br><span class="line">image = tf.cast(image, tf.float32) / <span class="number">255.0</span></span><br><span class="line">image = tf.subtract(image, <span class="number">0.5</span>)</span><br><span class="line">image = tf.multiply(image, <span class="number">2.0</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="图像大小调整"><a href="#图像大小调整" class="headerlink" title="图像大小调整"></a>图像大小调整</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调整图像大小，method有四中模式，可取值0,1,2,3</span></span><br><span class="line">image = tf.image.resize_images(image, [<span class="number">300</span>, <span class="number">300</span>], method=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>图像大小调整 tensorflow.image.resize_images 提供四种模式选择</p>
<ul>
<li>0：双线性插值</li>
<li>1：最近邻居法</li>
<li>2：双三次插值法</li>
<li>3：面积插值法</li>
</ul>
<p>先看原始图片：<br><img src="https://i.loli.net/2019/03/14/5c8a36879b6d5.png" alt="02_resize"></p>
<p>各种方法的对比结果：<br><img src="https://i.loli.net/2019/03/14/5c8a396eac8d3.png" alt="03_resize"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过tf.image.resize_image_with_crop_or_pad函数调整图像大小</span></span><br><span class="line">croped = tf.image.resize_image_with_crop_or_pad(image, <span class="number">1500</span>, <span class="number">1500</span>)</span><br><span class="line">padded = tf.image.resize_image_with_crop_or_pad(image, <span class="number">3500</span>, <span class="number">3500</span>)</span><br></pre></td></tr></table></figure>
<p>该函数有三个参数，<strong><code>images</code></strong> 表示原始图像，<strong><code>target_height</code></strong>   表示调整后目标图像高度，<strong><code>target_width</code></strong> 表示调整后目标图像宽度。如果原始图像尺寸大于目标图像，那么这个函数会自动截取原始图像居中的部分；反之，函数会自动在原始图像的四周填充全0背景。</p>
<p>输出结果：</p>
<p><img src="https://i.loli.net/2019/03/14/5c8a409fa81bb.png" alt="04_crop_pad"></p>
<h3 id="图像裁减"><a href="#图像裁减" class="headerlink" title="图像裁减"></a>图像裁减</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">通过tf.image.central_crop函数按比例裁减图像</span><br><span class="line">central_cropped = tf.image.central_crop(image, <span class="number">0.5</span>)</span><br></pre></td></tr></table></figure>
<p>该函数有两个参数，<strong><code>images</code></strong> 表示原始图像，<strong><code>central_fraction</code></strong> 表示调整比例。按比例裁减图像，参数 <strong><code>central_fraction</code></strong> 是一个介于 (0,1] 之间的实数，该函数也是自动截取中心部分。</p>
<p>输出结果：</p>
<p><img src="https://i.loli.net/2019/03/14/5c8a4346cfbed.png" alt="05_central_crop"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过tf.image.crop_to_bounding_box裁减图像</span></span><br><span class="line">crop_to = tf.image.crop_to_bounding_box(image, <span class="number">500</span>, <span class="number">500</span>, <span class="number">1000</span>, <span class="number">1000</span>)</span><br><span class="line"><span class="comment"># 通过tf.image.pad_to_bounding_box裁减图像</span></span><br><span class="line">pad_to = tf.image.pad_to_bounding_box(image, <span class="number">0</span>, <span class="number">0</span>, <span class="number">3500</span>, <span class="number">3500</span>)</span><br></pre></td></tr></table></figure>
<p>上述两个函数五参数相同，分别为：<strong><code>images</code></strong> 表示原始图像，<strong><code>offset_height</code></strong> 表示距离上边高度，<strong><code>offset_width</code></strong> 表示距离左边宽度，<strong><code>target_height</code></strong> 表示目标图像高度，<strong><code>target_width</code></strong> 表示目标图像宽度。</p>
<p><strong><code>crop_to_bounding_box</code></strong> 要求原始图像尺寸大于目标图像， <strong><code>pad_to_bounding_box</code></strong> 要求原始图像尺寸小于目标图像，并按照 <strong><code>offset_h</code></strong> / <strong><code>offset_w</code></strong> 的值截取或填充原始图像。</p>
<p>输出结果：</p>
<p><img src="https://i.loli.net/2019/03/14/5c8a4a1526dec.png" alt="06_bounding_box"></p>
<h3 id="图片翻转"><a href="#图片翻转" class="headerlink" title="图片翻转"></a>图片翻转</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 上下翻转</span></span><br><span class="line">flipped_up_down = tf.image.flip_up_down(image)</span><br><span class="line"><span class="comment"># 左右翻转</span></span><br><span class="line">flipped_left_right = tf.image.flip_left_right(image)</span><br><span class="line"><span class="comment"># 沿对角线翻转</span></span><br><span class="line">transposed = tf.image.transpose_image(image)</span><br><span class="line"><span class="comment"># 以50%的概率对图像上下翻转,左右翻转</span></span><br><span class="line">flipped = tf.image.random_flip_up_down(image)</span><br><span class="line">flipped = tf.image.random_flip_left_right(image)</span><br></pre></td></tr></table></figure>
<p>在很多图像识别问题中，图像的翻转不应该影响识别的结果。于是在训练神经网络模型时，可随机翻转训练图像，这样训练得到的模型可以识别不同角度的实体。</p>
<p>输出结果：</p>
<p><img src="https://i.loli.net/2019/03/14/5c8a4df832c2f.png" alt="07_flipped"></p>
<h3 id="图片色彩调整"><a href="#图片色彩调整" class="headerlink" title="图片色彩调整"></a>图片色彩调整</h3><h4 id="亮度"><a href="#亮度" class="headerlink" title="亮度"></a>亮度</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将图像亮度-0.5，并截断取值之0~1之间</span></span><br><span class="line">adjusted = tf.image.adjust_brightness(image, <span class="number">-0.5</span>)</span><br><span class="line">adjusted = tf.clip_by_value(adjusted, <span class="number">0.0</span>, <span class="number">1.0</span>)</span><br><span class="line"><span class="comment"># 在[-max_delta, max_delta]范围内随机调整图像亮度</span></span><br><span class="line">adjusted = tf.image.random_brightness(image, max_delta)</span><br></pre></td></tr></table></figure>
<p>函数 <strong><code>tf.image.adjust_brightness</code></strong> 包含两个参数， <strong><code>images</code></strong> 表示原始图像， <strong><code>delta</code></strong> 表示亮度大小。 <strong><code>delta</code></strong> 绝对值的范围应该在 <strong><code>[0,1)</code></strong> 之内色彩调整的API可能导致像素的实数值超出 0~1 的范围，所以要用上述第二个函数，将取值截断。否则不仅图像无法可视化，输入的神经网络训练质量也会受到影响。</p>
<p><img src="https://i.loli.net/2019/03/14/5c8a51a78f743.png" alt="08_bright"></p>
<h4 id="对比度"><a href="#对比度" class="headerlink" title="对比度"></a>对比度</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将图像的对比度减少到0.5倍或增加5倍</span></span><br><span class="line">adjusted = tf.image.adjust_contrast(image, <span class="number">5</span>)</span><br><span class="line"><span class="comment"># 在[lower, upper]的范围内随机调整图的对比度</span></span><br><span class="line">adjusted = tf.image.random_contrast(image, lower, upper)</span><br></pre></td></tr></table></figure>
<p>函数 <strong><code>tf.image.adjust_contrast</code></strong> 包含两个参数， <strong><code>images</code></strong> 表示原始图像， <strong><code>contrast_factor</code></strong> 表示对比度调整参数。</p>
<p>对比度的调整，官方文档解释如下：</p>
<blockquote>
<p>For each channel, this Op computes the mean of the image pixels in the channel and then adjusts each component x of each pixel to (x - mean) * contrast_factor + mean</p>
</blockquote>
<p>输出结果：</p>
<p><img src="https://i.loli.net/2019/03/14/5c8a565a649ff.png" alt="09_contrast"></p>
<h4 id="色相"><a href="#色相" class="headerlink" title="色相"></a>色相</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将图像的色相相加一个值,调整值在[-1, 1]之间</span></span><br><span class="line">adjusted = tf.image.adjust_hue(img_data, <span class="number">0.6</span>)</span><br><span class="line"><span class="comment"># 在[-max_delta, max_delta]的范围内随机调整图像的色相，max_delta的取值在[0, 0.5]之间</span></span><br><span class="line">adjusted = tf.image.random_hue(image, max_delta)</span><br></pre></td></tr></table></figure>
<p>函数 <strong><code>tf.image.adjust_hue</code></strong> 包含两个参数， <strong><code>images</code></strong> 表示原始图像， <strong><code>delta</code></strong> 表示增加的色相大小。</p>
<p>色相的调整，官方文档解释如下：</p>
<blockquote>
<p>image is an RGB image. The image hue is adjusted by converting the image to HSV and rotating the hue channel (H) by delta. The image is then converted back to RGB.</p>
</blockquote>
<p>输出结果：</p>
<p><img src="https://i.loli.net/2019/03/14/5c8a565ef0599.png" alt="10_hue"></p>
<h4 id="饱和度"><a href="#饱和度" class="headerlink" title="饱和度"></a>饱和度</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将图像的饱和度-5或+5</span></span><br><span class="line">adjusted = tf.image.adjust_saturation(img_data, <span class="number">5</span>)</span><br><span class="line"><span class="comment"># 在[lower, upper]的范围内随机调整图的饱和度</span></span><br><span class="line">adjusted = tf.image.random_saturation(image, lower, upper)</span><br></pre></td></tr></table></figure>
<p>函数 <strong><code>tf.image.adjust_saturation</code></strong> 包含两个参数， <strong><code>images</code></strong> 表示原始图像， <strong><code>saturation_factor</code></strong> 表示饱和度调整参数。</p>
<p>饱和度的调整，官方文档解释如下：</p>
<blockquote>
<p>image is an RGB image. The image saturation is adjusted by converting the image to HSV and multiplying the saturation (S) channel by saturation_factor and clipping. The image is then converted back to RGB.</p>
</blockquote>
<p>输出结果：</p>
<p><img src="https://i.loli.net/2019/03/14/5c8a583573050.png" alt="11_saturation"></p>
<h3 id="图像预处理完整样例"><a href="#图像预处理完整样例" class="headerlink" title="图像预处理完整样例"></a>图像预处理完整样例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">#### 1. 随机调整图片的色彩，定义两种顺序。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distort_color</span><span class="params">(image, color_ordering=<span class="number">0</span>)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> color_ordering == <span class="number">0</span>:</span><br><span class="line">        image = tf.image.random_brightness(image, max_delta=<span class="number">32.</span>/<span class="number">255.</span>)</span><br><span class="line">        image = tf.image.random_saturation(image, lower=<span class="number">0.5</span>, upper=<span class="number">1.5</span>)</span><br><span class="line">        image = tf.image.random_hue(image, max_delta=<span class="number">0.2</span>)</span><br><span class="line">        image = tf.image.random_contrast(image, lower=<span class="number">0.5</span>, upper=<span class="number">1.5</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        image = tf.image.random_saturation(image, lower=<span class="number">0.5</span>, upper=<span class="number">1.5</span>)</span><br><span class="line">        image = tf.image.random_brightness(image, max_delta=<span class="number">32.</span>/<span class="number">255.</span>)</span><br><span class="line">        image = tf.image.random_contrast(image, lower=<span class="number">0.5</span>, upper=<span class="number">1.5</span>)</span><br><span class="line">        image = tf.image.random_hue(image, max_delta=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tf.clip_by_value(image, <span class="number">0.0</span>, <span class="number">1.0</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#### 2. 对图片进行预处理，将图片转化成神经网络的输入层数据。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess_for_train</span><span class="params">(image, height, width, bbox)</span>:</span></span><br><span class="line">    <span class="comment"># 查看是否存在标注框。</span></span><br><span class="line">    <span class="keyword">if</span> bbox <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        bbox = tf.constant([<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>], dtype=tf.float32, shape=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>])</span><br><span class="line">    <span class="keyword">if</span> image.dtype != tf.float32:</span><br><span class="line">        image = tf.image.convert_image_dtype(image, dtype=tf.float32)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 随机的截取图片中一个块。</span></span><br><span class="line">    bbox_begin, bbox_size, _ = tf.image.sample_distorted_bounding_box(</span><br><span class="line">        tf.shape(image), bounding_boxes=bbox, min_object_covered=<span class="number">0.4</span>)</span><br><span class="line">    bbox_begin, bbox_size, _ = tf.image.sample_distorted_bounding_box(</span><br><span class="line">        tf.shape(image), bounding_boxes=bbox, min_object_covered=<span class="number">0.4</span>)</span><br><span class="line">    distorted_image = tf.slice(image, bbox_begin, bbox_size)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将随机截取的图片调整为神经网络输入层的大小。</span></span><br><span class="line">    distorted_image = tf.image.resize_images(distorted_image, [height, width], method=np.random.randint(<span class="number">4</span>))</span><br><span class="line">    distorted_image = tf.image.random_flip_left_right(distorted_image)</span><br><span class="line">    distorted_image = distort_color(distorted_image, np.random.randint(<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">return</span> distorted_image</span><br><span class="line">    </span><br><span class="line"><span class="comment">#### 3. 读取图片。</span></span><br><span class="line">image_raw_data = tf.gfile.FastGFile(<span class="string">"../../datasets/cat.jpg"</span>, <span class="string">"rb"</span>).read()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    img_data = tf.image.decode_jpeg(image_raw_data)</span><br><span class="line">    boxes = tf.constant([[[<span class="number">0.05</span>, <span class="number">0.05</span>, <span class="number">0.9</span>, <span class="number">0.7</span>], [<span class="number">0.35</span>, <span class="number">0.47</span>, <span class="number">0.5</span>, <span class="number">0.56</span>]]])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">9</span>):</span><br><span class="line">        result = preprocess_for_train(img_data, <span class="number">299</span>, <span class="number">299</span>, boxes)</span><br><span class="line">        plt.imshow(result.eval())</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="卷积神经网络-CNN"><a href="#卷积神经网络-CNN" class="headerlink" title="卷积神经网络 CNN"></a>卷积神经网络 CNN</h2><h3 id="定义卷积层"><a href="#定义卷积层" class="headerlink" title="定义卷积层"></a>定义卷积层</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一层卷积层神经网络，input为输入数据，filter为滤波器即权重，strides步长为1，padding可以取'SAME'和'VALID'</span></span><br><span class="line">conv2d = tf.nn.conv2d(input, filter, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="定义池化层"><a href="#定义池化层" class="headerlink" title="定义池化层"></a>定义池化层</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一层池化层神经网络，value为输入数据，ksize为池化窗口大小，strides步长为2，padding可以取'SAME'和'VALID'</span></span><br><span class="line">max_pool = tf.nn.max_pool(value, ksize=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>], strides=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br></pre></td></tr></table></figure>
<h2 id="循环神经网络-RNN"><a href="#循环神经网络-RNN" class="headerlink" title="循环神经网络 RNN"></a>循环神经网络 RNN</h2><h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化输出层权值</span></span><br><span class="line">weights = tf.Variable(tf.truncated_normal([lstm_size, n_classes], stddev=<span class="number">0.1</span>))</span><br><span class="line"><span class="comment"># 初始化输出层偏置值</span></span><br><span class="line">biases = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=[n_classes]))</span><br><span class="line"><span class="comment"># 定义一个LSTM单元，lstm_hidden_size为隐藏层节点数</span></span><br><span class="line">lstm_cell = tf.nn.rnn_cell.LSTMCell(lstm_hidden_size)</span><br><span class="line"><span class="comment"># 每一步处理时间序列的时刻，inputs为输入，outputs包含了所有时刻的输出h_t，final_state最后一个时刻的输出c_t和h_t</span></span><br><span class="line">outputs, final_state = tf.nn.dynamic_rnn(lstm_cell, inputs, dtype=tf.float32)</span><br><span class="line"><span class="comment"># 计算最后的结果</span></span><br><span class="line">results = tf.nn.softmax(tf.matmul(final_state[<span class="number">1</span>], weights) + biases)</span><br></pre></td></tr></table></figure>
<h2 id="模型的保存与载入"><a href="#模型的保存与载入" class="headerlink" title="模型的保存与载入"></a>模型的保存与载入</h2><p>使用tensorflow过程中，训练结束后我们需要用到模型文件。有时候，我们可能也需要用到别人训练好的模型，并在这个基础上再次训练。这时候我们需要掌握如何操作这些模型数据。看完本文，相信你一定会有收获！</p>
<h3 id="Tensorflow模型文件"><a href="#Tensorflow模型文件" class="headerlink" title="Tensorflow模型文件"></a>Tensorflow模型文件</h3><p>我们在checkpoint_dir目录下保存的文件结构如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--checkpoint_dir</span><br><span class="line">|    |--checkpoint</span><br><span class="line">|    |--MyModel.meta</span><br><span class="line">|    |--MyModel.data<span class="number">-00000</span>-of<span class="number">-00001</span></span><br><span class="line">|    |--MyModel.index</span><br></pre></td></tr></table></figure></p>
<h4 id="meta文件"><a href="#meta文件" class="headerlink" title="meta文件"></a>meta文件</h4><p>MyModel.meta文件保存的是图结构，meta文件是pb（protocol buffer）格式文件，包含变量、op、集合等。</p>
<h4 id="ckpt文件"><a href="#ckpt文件" class="headerlink" title="ckpt文件"></a>ckpt文件</h4><p>ckpt文件是二进制文件，保存了所有的weights、biases、gradients等变量。在tensorflow 0.11之前，保存在.ckpt文件中。0.11后，通过两个文件保存,如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MyModel.data<span class="number">-00000</span>-of<span class="number">-00001</span></span><br><span class="line">MyModel.index</span><br></pre></td></tr></table></figure></p>
<h4 id="checkpoint文件"><a href="#checkpoint文件" class="headerlink" title="checkpoint文件"></a>checkpoint文件</h4><p>我们还可以看，checkpoint_dir目录下还有checkpoint文件，该文件是个文本文件，里面记录了保存的最新的checkpoint文件以及其它checkpoint文件列表。在inference时，可以通过修改这个文件，指定使用哪个model。</p>
<h3 id="保存Tensorflow模型"><a href="#保存Tensorflow模型" class="headerlink" title="保存Tensorflow模型"></a>保存Tensorflow模型</h3><p>tensorflow 提供了 <strong><code>tf.train.Saver</code></strong> 类来保存模型，值得注意的是，在tensorflow中，变量是存在于Session环境中，也就是说，只有在Session环境下才会存有变量值，因此，保存模型时需要传入session：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">saver = tf.train.Saver()</span><br><span class="line">saver.save(sess,<span class="string">"./checkpoint_dir/MyModel"</span>)</span><br></pre></td></tr></table></figure>
<p>上面第二句写入会话中，执行后，在checkpoint_dir目录下创建模型文件如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">checkpoint</span><br><span class="line">MyModel.data<span class="number">-00000</span>-of<span class="number">-00001</span></span><br><span class="line">MyModel.index</span><br><span class="line">MyModel.meta</span><br></pre></td></tr></table></figure>
<p>另外，如果想要在1000次迭代后，再保存模型，只需设置global_step参数即可：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">saver.save(sess, <span class="string">'./checkpoint_dir/MyModel'</span>, global_step=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
<p>保存的模型文件名称会在后面加<code>-1000</code>,如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">checkpoint</span><br><span class="line">MyModel<span class="number">-1000.</span>data<span class="number">-00000</span>-of<span class="number">-00001</span></span><br><span class="line">MyModel<span class="number">-1000.</span>index</span><br><span class="line">MyModel<span class="number">-1000.</span>meta</span><br></pre></td></tr></table></figure>
<p>在实际训练中，我们可能会在每1000次迭代中保存一次模型数据，但是由于图是不变的，没必要每次都去保存，可以通过如下方式指定不保存图：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">saver.save(sess, <span class="string">'./checkpoint_dir/MyModel'</span>, global_step=step, write_meta_graph=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<p>另一种比较实用的是，如果你希望每2小时保存一次模型，并且只保存最近的5个模型文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.train.Saver(max_to_keep=<span class="number">5</span>, keep_checkpoint_every_n_hours=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>如果我们不对tf.train.Saver指定任何参数，默认会保存所有变量。如果你不想保存所有变量，而只保存一部分变量，可以通过指定variables/collections。在创建tf.train.Saver实例时，通过将需要保存的变量构造list或者dictionary，传入到Saver中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">w1 = tf.Variable(tf.random_normal(shape=[<span class="number">2</span>]), name=<span class="string">'w1'</span>)</span><br><span class="line">w2 = tf.Variable(tf.random_normal(shape=[<span class="number">5</span>]), name=<span class="string">'w2'</span>)</span><br><span class="line">saver = tf.train.Saver([w1,w2])</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line">saver.save(sess, <span class="string">'./checkpoint_dir/MyModel'</span>, global_step=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
<h3 id="导入训练好的模型"><a href="#导入训练好的模型" class="headerlink" title="导入训练好的模型"></a>导入训练好的模型</h3><p>在第1小节中我们介绍过，tensorflow将图和变量数据分开保存为不同的文件。因此，在导入模型时，也要分为2步：构造网络图和加载参数</p>
<h4 id="构造网络图"><a href="#构造网络图" class="headerlink" title="构造网络图"></a>构造网络图</h4><p>一个比较笨的方法是，手敲代码，实现跟模型一模一样的图结构。其实，我们既然已经保存了图，那就没必要在去手写一次图结构代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">saver=tf.train.import_meta_graph(<span class="string">'./checkpoint_dir/MyModel-1000.meta'</span>)</span><br></pre></td></tr></table></figure>
<p>上面一行代码，就把图加载进来了</p>
<h4 id="加载参数"><a href="#加载参数" class="headerlink" title="加载参数"></a>加载参数</h4><p>仅仅有图并没有用，更重要的是，我们需要前面训练好的模型参数（即weights、biases等），本文第2节提到过，变量值需要依赖于Session，因此在加载参数时，先要构造好Session：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">	<span class="comment"># 保存模型结构</span></span><br><span class="line">    saver = tf.train.import_meta_graph(<span class="string">'./checkpoint_dir/MyModel-1000.meta'</span>)</span><br><span class="line">	<span class="comment"># 加载模型参数</span></span><br><span class="line">    saver.restore(sess,tf.train.latest_checkpoint(<span class="string">'./checkpoint_dir'</span>))</span><br></pre></td></tr></table></figure></p>
<h4 id="使用恢复的模型"><a href="#使用恢复的模型" class="headerlink" title="使用恢复的模型"></a>使用恢复的模型</h4><p>前面我们理解了如何保存和恢复模型，很多时候，我们希望使用一些已经训练好的模型，如prediction、fine-tuning以及进一步训练等。这时候，我们可能需要获取训练好的模型中的一些中间结果值，可以通过graph.get_tensor_by_name(‘w1:0’)来获取，注意w1:0是tensor的name。</p>
<p>假设我们有一个简单的网络模型，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 载入数据集</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data"</span>, one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 批次大小</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line"><span class="comment"># 计算一个周期一共有多少个批次</span></span><br><span class="line">n_batch = mnist.train.num_examples // batch_size</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义两个placeholder</span></span><br><span class="line">x = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">784</span>], name=<span class="string">'x_input'</span>)</span><br><span class="line">y = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">10</span>], name=<span class="string">'y_input'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个简单的神经网络:784-10</span></span><br><span class="line">W = tf.Variable(tf.truncated_normal([<span class="number">784</span>,<span class="number">10</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>]) + <span class="number">0.1</span>)</span><br><span class="line">prediction = tf.nn.softmax(tf.matmul(x,W)+b, name=<span class="string">'output'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 二次代价函数</span></span><br><span class="line">loss = tf.losses.mean_squared_error(y, prediction)</span><br><span class="line"><span class="comment"># 使用梯度下降法</span></span><br><span class="line">train = tf.train.AdamOptimizer(<span class="number">0.001</span>).minimize(loss, name=<span class="string">'train'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果存放在一个布尔型列表中</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y,<span class="number">1</span>),tf.argmax(prediction,<span class="number">1</span>))</span><br><span class="line"><span class="comment"># 求准确率</span></span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32), name=<span class="string">'accuracy'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建一个Saver对象，用于保存所有变量</span></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># 变量初始化</span></span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    <span class="comment"># 周期epoch：所有数据训练一次，就是一个周期</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">21</span>):</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> range(n_batch):</span><br><span class="line">            <span class="comment"># 获取一个批次的数据和标签</span></span><br><span class="line">            batch_xs,batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">            sess.run(train,feed_dict=&#123;x:batch_xs,y:batch_ys&#125;)</span><br><span class="line">        <span class="comment"># 每训练一个周期做一次测试</span></span><br><span class="line">        acc = sess.run(accuracy,feed_dict=&#123;x:mnist.test.images,y:mnist.test.labels&#125;)</span><br><span class="line">        print(<span class="string">"Iter "</span> + str(epoch) + <span class="string">",Testing Accuracy "</span> + str(acc))</span><br><span class="line">    saver.save(sess, <span class="string">'./checkpoint_dir/MyModel'</span>, global_step=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
<p>接下来我们使用<code>graph.get_tensor_by_name()</code>方法来操纵这个保存的模型。用<code>graph.get_tensor_by_name()</code>方法来获取之前模型定义的操作。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 载入数据集</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data"</span>, one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 批次大小</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line"><span class="comment"># 计算一个周期一共有多少个批次</span></span><br><span class="line">n_batch = mnist.train.num_examples // batch_size</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># 载入模型结构</span></span><br><span class="line">    saver = tf.train.import_meta_graph(<span class="string">'./checkpoint_dir/MyModel-1000.meta'</span>)</span><br><span class="line">    <span class="comment"># 载入模型参数</span></span><br><span class="line">    saver.restore(sess, tf.train.latest_checkpoint(<span class="string">'./checkpoint_dir'</span>))</span><br><span class="line">    <span class="comment"># 根据tensor的名字获取对应的tensor</span></span><br><span class="line">    output = sess.graph.get_tensor_by_name(<span class="string">"output:0"</span>)</span><br><span class="line">    <span class="comment"># 之前模型保存时的准确率计算</span></span><br><span class="line">    accuracy = sess.graph.get_tensor_by_name(<span class="string">"accuracy:0"</span>)</span><br><span class="line">    <span class="comment"># 之前模型保存时模型训练保存为train</span></span><br><span class="line">    train = sess.graph.get_operation_by_name(<span class="string">"train"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 把测试数据喂到网络中计算准确率</span></span><br><span class="line">    <span class="comment"># 'x_input'是模型数据的输入，'y_input'是模型标签的输入</span></span><br><span class="line">    print(sess.run(accuracy,feed_dict=&#123;<span class="string">'x_input:0'</span>:mnist.test.images, <span class="string">'y_input:0'</span>:mnist.test.labels&#125;))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 周期epoch：所有数据训练一次，就是一个周期</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">21</span>):</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> range(n_batch):</span><br><span class="line">            <span class="comment"># 获取一个批次的数据和标签</span></span><br><span class="line">            batch_xs,batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">            sess.run(train,feed_dict=&#123;<span class="string">'x_input:0'</span>:batch_xs, <span class="string">'y_input:0'</span>:batch_ys&#125;)</span><br><span class="line">        <span class="comment"># 每训练一个周期做一次测试</span></span><br><span class="line">        acc = sess.run(accuracy, feed_dict=&#123;<span class="string">'x_input:0'</span>:mnist.test.images, <span class="string">'y_input:0'</span>:mnist.test.labels&#125;)</span><br><span class="line">        print(<span class="string">"Iter "</span> + str(epoch) + <span class="string">",Testing Accuracy "</span> + str(acc))</span><br></pre></td></tr></table></figure>
<p>注意：保存模型时，只会保存变量的值，placeholder里面的值不会被保存。若没有<code>./checkpoint_dir/MyModel-1000.meta</code>文件，则需要手动编写模型结构代码。</p>
<h3 id="第二种保存Tensorflow模型方式"><a href="#第二种保存Tensorflow模型方式" class="headerlink" title="第二种保存Tensorflow模型方式"></a>第二种保存Tensorflow模型方式</h3><p>模型训练好后，直接在Session的最后写入：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存模型参数和结构，把变量变成常量</span></span><br><span class="line"><span class="comment"># output_node_names设置可以输出tensor</span></span><br><span class="line">output_graph_def = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def, output_node_names=[<span class="string">'output'</span>, <span class="string">'accuracy'</span>])</span><br><span class="line"><span class="comment"># 保存模型到目录的models文件夹</span></span><br><span class="line"><span class="keyword">with</span> tf.gfile.FastGFile(<span class="string">'pb_models/my_model.pb'</span>, mode=<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(output_graph_def.SerializeToString())</span><br></pre></td></tr></table></figure></p>
<h3 id="第二种模型载入方式"><a href="#第二种模型载入方式" class="headerlink" title="第二种模型载入方式"></a>第二种模型载入方式</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 载入数据集</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data"</span>, one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 载入模型</span></span><br><span class="line"><span class="keyword">with</span> tf.gfile.FastGFile(<span class="string">'pb_models/my_model.pb'</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="comment"># 创建一个图</span></span><br><span class="line">    graph_def = tf.GraphDef()</span><br><span class="line">    <span class="comment"># 把模型文件载入到图中</span></span><br><span class="line">    graph_def.ParseFromString(f.read())</span><br><span class="line">    <span class="comment"># 载入图到当前环境中</span></span><br><span class="line">    tf.import_graph_def(graph_def, name=<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># 根据tensor的名字获取对应的tensor</span></span><br><span class="line">    output = sess.graph.get_tensor_by_name(<span class="string">"output:0"</span>)</span><br><span class="line">    <span class="comment"># 之前模型保存时的准确率计算</span></span><br><span class="line">    accuracy = sess.graph.get_tensor_by_name(<span class="string">"accuracy:0"</span>)</span><br><span class="line">    <span class="comment"># 之前模型保存时模型训练保存为train</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 把测试数据喂到网络中计算准确率</span></span><br><span class="line">    <span class="comment"># 'x_input'是模型数据的输入，'y_input'是模型标签的输入</span></span><br><span class="line">    print(sess.run(accuracy,feed_dict=&#123;<span class="string">'x_input:0'</span>:mnist.test.images, <span class="string">'y_input:0'</span>:mnist.test.labels&#125;))</span><br></pre></td></tr></table></figure>
<p>第二种模型载入方式，比较简单，但是由于载入的常量，所以模型只能用于做预测，而不能用来做训练。</p>
<h2 id="Tensorbord"><a href="#Tensorbord" class="headerlink" title="Tensorbord"></a>Tensorbord</h2><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><h3 id="记录数据"><a href="#记录数据" class="headerlink" title="记录数据"></a>记录数据</h3><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>官网：<a href="https://www.tensorflow.org/api_docs/python/tf" target="_blank" rel="noopener">https://www.tensorflow.org/api_docs/python/tf</a></p>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>坚持原创技术分享，您的支持将鼓励我继续创作！</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.png" alt="Luo Teng 微信支付">
        <p>微信支付</p>
      </div>
    

    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/code/" rel="tag"># code</a>
          
            <a href="/tags/tensorflow/" rel="tag"># tensorflow</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/02/15/28张知识图谱，总结吴恩达-deeplearning-ai-课程/" rel="next" title="28张知识图谱，总结吴恩达 deeplearning.ai 课程">
                <i class="fa fa-chevron-left"></i> 28张知识图谱，总结吴恩达 deeplearning.ai 课程
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/03/12/卷积神经网络-CNN-模型/" rel="prev" title="卷积神经网络 CNN 模型">
                卷积神经网络 CNN 模型 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Luo Teng</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">39</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">19</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">59</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/tengzi-will" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.zhihu.com/people/ke-le-teng-zi/activities" target="_blank" title="知乎">
                      
                        <i class="fa fa-fw fa-globe"></i>知乎</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://mumaxu.github.io/" title="mamaxu" target="_blank">mamaxu</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://sunyancn.github.io/" title="sunyan" target="_blank">sunyan</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#基础"><span class="nav-number">1.</span> <span class="nav-text">基础</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#创建常量"><span class="nav-number">1.1.</span> <span class="nav-text">创建常量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#定义变量"><span class="nav-number">1.2.</span> <span class="nav-text">定义变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#运算"><span class="nav-number">1.3.</span> <span class="nav-text">运算</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#基本运算"><span class="nav-number">1.3.1.</span> <span class="nav-text">基本运算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#逻辑运算"><span class="nav-number">1.3.2.</span> <span class="nav-text">逻辑运算</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#所有变量初始化"><span class="nav-number">1.4.</span> <span class="nav-text">所有变量初始化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建会话"><span class="nav-number">1.5.</span> <span class="nav-text">创建会话</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Fetch-amp-Feed"><span class="nav-number">1.6.</span> <span class="nav-text">Fetch &amp; Feed</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#神经网络"><span class="nav-number">2.</span> <span class="nav-text">神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#变量初始化器"><span class="nav-number">2.1.</span> <span class="nav-text">变量初始化器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#激活函数"><span class="nav-number">2.2.</span> <span class="nav-text">激活函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#损失函数"><span class="nav-number">2.3.</span> <span class="nav-text">损失函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#防止过拟合"><span class="nav-number">2.4.</span> <span class="nav-text">防止过拟合</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Dropout"><span class="nav-number">2.4.1.</span> <span class="nav-text">Dropout</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#正则化"><span class="nav-number">2.4.2.</span> <span class="nav-text">正则化</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#优化器"><span class="nav-number">2.5.</span> <span class="nav-text">优化器</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#其他优化器"><span class="nav-number">2.5.1.</span> <span class="nav-text">其他优化器</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图片预处理"><span class="nav-number">3.</span> <span class="nav-text">图片预处理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#图像解码"><span class="nav-number">3.1.</span> <span class="nav-text">图像解码</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#图像大小调整"><span class="nav-number">3.2.</span> <span class="nav-text">图像大小调整</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#图像裁减"><span class="nav-number">3.3.</span> <span class="nav-text">图像裁减</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#图片翻转"><span class="nav-number">3.4.</span> <span class="nav-text">图片翻转</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#图片色彩调整"><span class="nav-number">3.5.</span> <span class="nav-text">图片色彩调整</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#亮度"><span class="nav-number">3.5.1.</span> <span class="nav-text">亮度</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#对比度"><span class="nav-number">3.5.2.</span> <span class="nav-text">对比度</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#色相"><span class="nav-number">3.5.3.</span> <span class="nav-text">色相</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#饱和度"><span class="nav-number">3.5.4.</span> <span class="nav-text">饱和度</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#图像预处理完整样例"><span class="nav-number">3.6.</span> <span class="nav-text">图像预处理完整样例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#卷积神经网络-CNN"><span class="nav-number">4.</span> <span class="nav-text">卷积神经网络 CNN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#定义卷积层"><span class="nav-number">4.1.</span> <span class="nav-text">定义卷积层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#定义池化层"><span class="nav-number">4.2.</span> <span class="nav-text">定义池化层</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#循环神经网络-RNN"><span class="nav-number">5.</span> <span class="nav-text">循环神经网络 RNN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#LSTM"><span class="nav-number">5.1.</span> <span class="nav-text">LSTM</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型的保存与载入"><span class="nav-number">6.</span> <span class="nav-text">模型的保存与载入</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Tensorflow模型文件"><span class="nav-number">6.1.</span> <span class="nav-text">Tensorflow模型文件</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#meta文件"><span class="nav-number">6.1.1.</span> <span class="nav-text">meta文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ckpt文件"><span class="nav-number">6.1.2.</span> <span class="nav-text">ckpt文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#checkpoint文件"><span class="nav-number">6.1.3.</span> <span class="nav-text">checkpoint文件</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#保存Tensorflow模型"><span class="nav-number">6.2.</span> <span class="nav-text">保存Tensorflow模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#导入训练好的模型"><span class="nav-number">6.3.</span> <span class="nav-text">导入训练好的模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#构造网络图"><span class="nav-number">6.3.1.</span> <span class="nav-text">构造网络图</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#加载参数"><span class="nav-number">6.3.2.</span> <span class="nav-text">加载参数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用恢复的模型"><span class="nav-number">6.3.3.</span> <span class="nav-text">使用恢复的模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#第二种保存Tensorflow模型方式"><span class="nav-number">6.4.</span> <span class="nav-text">第二种保存Tensorflow模型方式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#第二种模型载入方式"><span class="nav-number">6.5.</span> <span class="nav-text">第二种模型载入方式</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Tensorbord"><span class="nav-number">7.</span> <span class="nav-text">Tensorbord</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#网络结构"><span class="nav-number">7.1.</span> <span class="nav-text">网络结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#记录数据"><span class="nav-number">7.2.</span> <span class="nav-text">记录数据</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考链接"><span class="nav-number">8.</span> <span class="nav-text">参考链接</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Luo Teng</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  


  

  

</body>
</html>
