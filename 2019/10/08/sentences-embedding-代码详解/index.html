<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|Menlo:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="句向量,sentences embedding,NLP,">










<meta name="description" content="下载数据集kaggle 链接下载地址 如果下载速度慢或者总是出现错误，参见博客服务器快速下载 kaggle 数据集攻略 程序文件说明 get_all_data.py model.py main.py  数据预处理 切词：使用 nltk 工具将文档切分成一个一个的词 统计单词：统计预料中出现的单词频率并根据频率构建词表 分配ID：为每一个单词分配一个 ID 编号表示：将程序所需数据集文本转化为用单词">
<meta name="keywords" content="句向量,sentences embedding,NLP">
<meta property="og:type" content="article">
<meta property="og:title" content="sentences embedding 代码详解">
<meta property="og:url" content="http://yoursite.com/2019/10/08/sentences-embedding-代码详解/index.html">
<meta property="og:site_name" content="LuoTeng&#39;s Blog">
<meta property="og:description" content="下载数据集kaggle 链接下载地址 如果下载速度慢或者总是出现错误，参见博客服务器快速下载 kaggle 数据集攻略 程序文件说明 get_all_data.py model.py main.py  数据预处理 切词：使用 nltk 工具将文档切分成一个一个的词 统计单词：统计预料中出现的单词频率并根据频率构建词表 分配ID：为每一个单词分配一个 ID 编号表示：将程序所需数据集文本转化为用单词">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2019-10-21T07:11:28.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="sentences embedding 代码详解">
<meta name="twitter:description" content="下载数据集kaggle 链接下载地址 如果下载速度慢或者总是出现错误，参见博客服务器快速下载 kaggle 数据集攻略 程序文件说明 get_all_data.py model.py main.py  数据预处理 切词：使用 nltk 工具将文档切分成一个一个的词 统计单词：统计预料中出现的单词频率并根据频率构建词表 分配ID：为每一个单词分配一个 ID 编号表示：将程序所需数据集文本转化为用单词">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/10/08/sentences-embedding-代码详解/">





  <title>sentences embedding 代码详解 | LuoTeng's Blog</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">LuoTeng's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">每一个不曾起舞的日子都是对生命的辜负</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/08/sentences-embedding-代码详解/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Luo Teng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LuoTeng's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">sentences embedding 代码详解</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-08T17:01:26+08:00">
                2019-10-08
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/自然语言处理/" itemprop="url" rel="index">
                    <span itemprop="name">自然语言处理</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="下载数据集"><a href="#下载数据集" class="headerlink" title="下载数据集"></a>下载数据集</h2><p><a href="https://www.kaggle.com/iarunava/imdb-movie-reviews-dataset" target="_blank" rel="noopener">kaggle 链接下载地址</a></p>
<p>如果下载速度慢或者总是出现错误，参见博客<a href="https://tengzi-will.github.io/2019/10/09/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%BF%AB%E9%80%9F%E4%B8%8B%E8%BD%BD-kaggle-%E6%95%B0%E6%8D%AE%E9%9B%86%E6%94%BB%E7%95%A5/#more" target="_blank" rel="noopener">服务器快速下载 kaggle 数据集攻略</a></p>
<h2 id="程序文件说明"><a href="#程序文件说明" class="headerlink" title="程序文件说明"></a>程序文件说明</h2><ul>
<li>get_all_data.py</li>
<li>model.py</li>
<li>main.py</li>
</ul>
<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><ul>
<li><strong>切词</strong>：使用 nltk 工具将文档切分成一个一个的词</li>
<li><strong>统计单词</strong>：统计预料中出现的单词频率并根据频率构建词表</li>
<li><strong>分配ID</strong>：为每一个单词分配一个 ID</li>
<li><strong>编号表示</strong>：将程序所需数据集文本转化为用单词编号的形式表示</li>
<li><strong>窗口数据集构建</strong>：按照窗口大小构建本次模型训练所需要的数据集</li>
</ul>
<p>以下代码存放在 <strong><code>get_all_data.py</code></strong> 文件中<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># from nltk.book import *</span></span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dataset</span><span class="params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">"./data/train_word_datas"</span>):</span><br><span class="line">            train_datas, train_labels, train_unsup, test_datas, test_labels = self.get_all_datas()</span><br><span class="line">            word2id = self.get_all_words(train_datas, train_unsup)</span><br><span class="line">            train_datas = self.convert_data_word_to_id(word2id, train_datas)</span><br><span class="line">            train_unsup = self.convert_data_word_to_id(word2id, train_unsup)</span><br><span class="line">            test_datas = self.convert_data_word_to_id(word2id, test_datas)</span><br><span class="line">            self.train_datas = train_datas</span><br><span class="line">            self.train_labels = train_labels</span><br><span class="line">            self.train_unsup = train_unsup</span><br><span class="line">            self.test_datas = test_datas</span><br><span class="line">            self.test_labels = test_labels</span><br><span class="line">            <span class="comment"># 这里可以只是self.train_datas，也可以是self.train_datas+self.train_unsup</span></span><br><span class="line">            new_word_datas, new_papr_datas, new_labels = self.convert_data_to_new_data(self.train_datas)</span><br><span class="line">            self.train_word_datas = new_word_datas</span><br><span class="line">            self.train_para_datas = new_papr_datas</span><br><span class="line">            self.train_new_labels = new_labels</span><br><span class="line">            new_word_datas, new_papr_datas, new_labels = self.convert_data_to_new_data(self.test_datas)</span><br><span class="line">            self.test_word_datas = new_word_datas</span><br><span class="line">            self.test_para_datas = new_papr_datas</span><br><span class="line">            self.test_new_labels = new_labels</span><br><span class="line">            pickle.dump(self.train_word_datas, open(<span class="string">"./data/train_word_datas"</span>, <span class="string">"wb"</span>))</span><br><span class="line">            pickle.dump(self.train_para_datas, open(<span class="string">"./data/train_para_datas"</span>, <span class="string">"wb"</span>))</span><br><span class="line">            pickle.dump(self.train_new_labels, open(<span class="string">"./data/train_new_labels"</span>, <span class="string">"wb"</span>))</span><br><span class="line">            pickle.dump(self.train_labels, open(<span class="string">"./data/train_labels"</span>, <span class="string">"wb"</span>))</span><br><span class="line">            pickle.dump(self.test_word_datas, open(<span class="string">"./data/test_word_datas"</span>, <span class="string">"wb"</span>))</span><br><span class="line">            pickle.dump(self.test_para_datas, open(<span class="string">"./data/test_para_datas"</span>, <span class="string">"wb"</span>))</span><br><span class="line">            pickle.dump(self.test_new_labels, open(<span class="string">"./data/test_new_labels"</span>, <span class="string">"wb"</span>))</span><br><span class="line">            pickle.dump(self.test_labels, open(<span class="string">"./data/test_labels"</span>, <span class="string">"wb"</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.train_word_datas = pickle.load(open(<span class="string">"./data/train_word_datas"</span>, <span class="string">"rb"</span>))</span><br><span class="line">            self.train_para_datas = pickle.load(open(<span class="string">"./data/train_para_datas"</span>, <span class="string">"rb"</span>))</span><br><span class="line">            self.train_para_datas = self.train_para_datas.reshape([self.train_para_datas.shape[<span class="number">0</span>],<span class="number">1</span>])</span><br><span class="line">            self.train_new_labels = pickle.load(open(<span class="string">"./data/train_new_labels"</span>, <span class="string">"rb"</span>))</span><br><span class="line">            self.train_labels = pickle.load(open(<span class="string">"./data/train_labels"</span>, <span class="string">"rb"</span>))</span><br><span class="line">            self.test_word_datas = pickle.load(open(<span class="string">"./data/test_word_datas"</span>, <span class="string">"rb"</span>))</span><br><span class="line">            self.test_para_datas = pickle.load(open(<span class="string">"./data/test_para_datas"</span>, <span class="string">"rb"</span>))</span><br><span class="line">            self.test_para_datas = self.test_para_datas.reshape([self.test_para_datas.shape[<span class="number">0</span>], <span class="number">1</span>])</span><br><span class="line">            self.test_new_labels = pickle.load(open(<span class="string">"./data/test_new_labels"</span>, <span class="string">"rb"</span>))</span><br><span class="line">            self.test_labels = pickle.load(open(<span class="string">"./data/test_labels"</span>, <span class="string">"rb"</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_data</span><span class="params">(self, path)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        根据文件的路径读取文件路径下的所有文件</span></span><br><span class="line"><span class="string">        :param path: 文件路径</span></span><br><span class="line"><span class="string">        :return: 所有的文本数据</span></span><br><span class="line"><span class="string">        nltk如果出现错误，可以先装nltk，然后在python中输入nltk.download("popular")</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        datas = []</span><br><span class="line">        paths = os.listdir(path)</span><br><span class="line">        paths = [path +file_name <span class="keyword">for</span> file_name <span class="keyword">in</span> paths]</span><br><span class="line">        <span class="keyword">for</span> i, file <span class="keyword">in</span> enumerate(paths):</span><br><span class="line">            <span class="keyword">if</span> i%<span class="number">1000</span>==<span class="number">0</span>:</span><br><span class="line">                <span class="keyword">print</span> (i, len(paths))</span><br><span class="line">            data = open(file, <span class="string">"r"</span>).read()</span><br><span class="line">            data = data.lower()</span><br><span class="line">            data = nltk.word_tokenize(data)</span><br><span class="line">            datas.append(data)</span><br><span class="line">        <span class="keyword">return</span> datas</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_all_datas</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        得到所有的训练句子，无监督句子和测试句子。</span></span><br><span class="line"><span class="string">        :return: 返回训练句子，训练标签，无监督句子，测试句子，测试标签</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        train_neg_datas = self.get_data(path=<span class="string">"data/aclImdb/train/neg/"</span>)</span><br><span class="line">        train_pos_datas = self.get_data(path=<span class="string">"data/aclImdb/train/pos/"</span>)</span><br><span class="line">        train_unsup = self.get_data(path=<span class="string">"data/aclImdb/train/unsup/"</span>)</span><br><span class="line">        test_neg_datas = self.get_data(path = <span class="string">"data/aclImdb/test/neg/"</span>)</span><br><span class="line">        test_pos_datas = self.get_data(path=<span class="string">"data/aclImdb/test/pos/"</span>)</span><br><span class="line">        train_datas = train_neg_datas+train_pos_datas</span><br><span class="line">        train_labels = [<span class="number">0</span>]*len(train_neg_datas)+[<span class="number">1</span>]*len(train_pos_datas)</span><br><span class="line">        test_datas = test_neg_datas+train_pos_datas</span><br><span class="line">        test_labels = [<span class="number">0</span>]*len(test_neg_datas)+[<span class="number">1</span>]*len(test_pos_datas)</span><br><span class="line">        tmp = list(zip(train_datas, train_labels))</span><br><span class="line">        random.shuffle(tmp)</span><br><span class="line">        train_datas[:], train_labels[:] = zip(*tmp)</span><br><span class="line">        tmp = list(zip(test_datas, test_labels))</span><br><span class="line">        random.shuffle(tmp)</span><br><span class="line">        test_datas[:], test_labels[:] = zip(*tmp)</span><br><span class="line">        print(len(train_datas), len(train_labels))</span><br><span class="line">        print(len(train_unsup))</span><br><span class="line">        print(len(test_datas), len(test_labels))</span><br><span class="line">        <span class="keyword">return</span> train_datas, train_labels, train_unsup, test_datas, test_labels</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_all_words</span><span class="params">(self, train_datas, train_unsup)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        从训练句子和无监督句子中统计所有出现过的词以及它们的频率并取出现频率最高的29998个词加上pad和unk构建一个30000大小的词表</span></span><br><span class="line"><span class="string">        :param train_datas: 所有的训练句子</span></span><br><span class="line"><span class="string">        :param train_unsup: 所有的无监督句子</span></span><br><span class="line"><span class="string">        :return: 30000大小的词典，每个词对应一个id</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        all_words = []</span><br><span class="line">        <span class="keyword">for</span> sentence <span class="keyword">in</span> train_datas:</span><br><span class="line">            all_words.extend(sentence)</span><br><span class="line">        <span class="keyword">for</span> sentence <span class="keyword">in</span> train_unsup:</span><br><span class="line">            all_words.extend(sentence)</span><br><span class="line">        count = Counter(all_words)</span><br><span class="line">        count = dict(count.most_common(<span class="number">29998</span>))</span><br><span class="line">        word2id = &#123;<span class="string">"&lt;pad&gt;"</span>: <span class="number">0</span>, <span class="string">"&lt;unk&gt;"</span>: <span class="number">1</span>&#125;</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> count:</span><br><span class="line">            word2id[word] = len(word2id)</span><br><span class="line">        <span class="keyword">return</span> word2id</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">convert_data_word_to_id</span><span class="params">(self, word2id, datas)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        将datas里面的词都转化正对应的id</span></span><br><span class="line"><span class="string">        :param word2id: 30000大小的词典</span></span><br><span class="line"><span class="string">        :param datas: 需要转化的数据</span></span><br><span class="line"><span class="string">        :return: 返回转化完的数据</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">for</span> i, sentence <span class="keyword">in</span> enumerate(datas):</span><br><span class="line">            <span class="keyword">for</span> j, word <span class="keyword">in</span> enumerate(sentence):</span><br><span class="line">                datas[i][j] = word2id.get(word, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> datas</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">convert_data_to_new_data</span><span class="params">(self, datas)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        根据句子生成窗口大小为10的语言模型训练集，当句子长度不够10时需要在前面补pad。</span></span><br><span class="line"><span class="string">        :param datas: 句子，可以只使用训练句子，也可以使用训练句子+无监督句子，后续需要训练更久。</span></span><br><span class="line"><span class="string">        :return: 返回窗口大小为10的训练集，句子id和词标签。</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        new_word_datas = []</span><br><span class="line">        new_papr_datas = []</span><br><span class="line">        new_labels = []</span><br><span class="line">        <span class="keyword">for</span> i, data <span class="keyword">in</span> enumerate(datas):</span><br><span class="line">            <span class="keyword">if</span> i%<span class="number">1000</span>==<span class="number">0</span>:</span><br><span class="line">                print(i, len(datas))</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(len(data)):</span><br><span class="line">                <span class="keyword">if</span> len(data)&lt;<span class="number">10</span>: <span class="comment"># 如果句子长度不够10，开始pad</span></span><br><span class="line">                    tmp_words = [<span class="number">0</span>]*(<span class="number">10</span>-len(data))+data[<span class="number">0</span>:<span class="number">-1</span>]</span><br><span class="line">                    <span class="keyword">if</span> set(tmp_words)==&#123;<span class="number">1</span>&#125;: <span class="comment">#同样，连续9个词都是unk就舍去</span></span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line">                    new_word_datas.append(tmp_words)</span><br><span class="line">                    new_papr_datas.append(i)</span><br><span class="line">                    new_labels.append(data[<span class="number">-1</span>])</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                tmp_words = data[j: j+<span class="number">9</span>]</span><br><span class="line">                <span class="keyword">if</span> set(tmp_words)==&#123;<span class="number">1</span>&#125;: <span class="comment"># 开始发现存在连续出现unk的句子，这种句子没有意义，所以连续9个词都是unk，那么就舍去</span></span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                new_papr_datas.append(i)</span><br><span class="line">                new_word_datas.append(tmp_words)</span><br><span class="line">                new_labels.append(data[j+<span class="number">9</span>])</span><br><span class="line">                <span class="keyword">if</span> j+<span class="number">9</span>+<span class="number">1</span>==len(data): <span class="comment"># 到最后10个单词break</span></span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">        new_word_datas = np.array(new_word_datas)</span><br><span class="line">        new_papr_datas = np.array(new_papr_datas)</span><br><span class="line">        new_labels = np.array(new_labels)</span><br><span class="line">        print(new_word_datas.shape)</span><br><span class="line">        print(new_papr_datas.shape)</span><br><span class="line">        print(new_labels.shape)</span><br><span class="line">        <span class="keyword">return</span> new_word_datas, new_papr_datas, new_labels</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment"># nltk.download('punkt')</span></span><br><span class="line">    data = Dataset()</span><br></pre></td></tr></table></figure></p>
<p>运行代码后自动生成预处理好的数据集。这里强调一点，代码可能包错，需要下载 <strong><code>nltk</code></strong> 的工具包，若按照官方文档的下载方式一定会出问题，建议在网上找别人下载好的数据包，自己解压到指定目录即可。(nltk 工具包链接后面会给出)</p>
<p>这里主要用的是 <strong><code>punkt</code></strong> 包中的 <strong><code>english.pickle</code></strong> 文件，我放的目录路径是 <strong><code>home/luoteng/nltk_data/tokenizers/punkt/PY3/english.pickle</code></strong> 。文件存放目录不对，程序会报错。</p>
<h2 id="模型构建"><a href="#模型构建" class="headerlink" title="模型构建"></a>模型构建</h2><p>以下代码存放在 <strong><code>model.py</code></strong> 文件中<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">model</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, train_first, train_second)</span>:</span></span><br><span class="line">        self.window = <span class="number">10</span> <span class="comment"># 使用连续的9个词预测下一个词</span></span><br><span class="line">        self.para_num = <span class="number">75000</span></span><br><span class="line">        self.create_placeholder()</span><br><span class="line">        self.model(train_first, train_second)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">create_placeholder</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        创建图的输入placeholder</span></span><br><span class="line"><span class="string">        self.word_input: n-gram前n-1个词的输入</span></span><br><span class="line"><span class="string">        self.para_input：篇章id的输入</span></span><br><span class="line"><span class="string">        self.word_label: 语言模型预测下一个词的词标签</span></span><br><span class="line"><span class="string">        self.label：这句话属于正类还是负类的类别标签</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        self.word_input = tf.placeholder(dtype=tf.int32, shape=[<span class="keyword">None</span>, self.window<span class="number">-1</span>])</span><br><span class="line">        self.para_input = tf.placeholder(dtype=tf.int32, shape=[<span class="keyword">None</span>, <span class="number">1</span>])</span><br><span class="line">        self.word_label = tf.placeholder(dtype=tf.int32, shape=[<span class="keyword">None</span>])</span><br><span class="line">        self.label = tf.placeholder(dtype=tf.int32, shape=[<span class="keyword">None</span>])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(self, train_first, train_second)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        :param train_first: 当train_first为True时，表示训练训练集的词向量和句向量</span></span><br><span class="line"><span class="string">        :param train_second:  当train_second为True时，表示固定词向量和句向量，开始训练单隐层神经网络分类器用于情感分类</span></span><br><span class="line"><span class="string">        当train_first和train_second都是False的时候表示测试阶段</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">"train_parameters"</span>):</span><br><span class="line">            self.train_para_embedding = tf.Variable(initial_value=tf.truncated_normal(shape=[self.para_num, <span class="number">400</span>]),</span><br><span class="line">                                                    trainable=<span class="keyword">True</span>, name=<span class="string">"train_para_embedding"</span>)</span><br><span class="line">            self.word_embedding = tf.Variable(initial_value=tf.truncated_normal(shape=[<span class="number">30000</span>, <span class="number">400</span>]),</span><br><span class="line">                                              trainable=<span class="keyword">True</span>, name=<span class="string">"word_embedding"</span>)</span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">"test_parameters"</span>):</span><br><span class="line">            self.test_para_embedding = tf.Variable(initial_value=tf.truncated_normal(shape=[<span class="number">25000</span>, <span class="number">400</span>]), trainable=<span class="keyword">True</span>,</span><br><span class="line">                                                   name=<span class="string">"test_para_embedding"</span>)</span><br><span class="line">        <span class="keyword">if</span> train_first <span class="keyword">or</span> train_second:</span><br><span class="line">            para_input = tf.nn.embedding_lookup(self.train_para_embedding, self.para_input)  <span class="comment"># batch_size*1*400</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            para_input = tf.nn.embedding_lookup(self.test_para_embedding, self.para_input)</span><br><span class="line">        word_inut = tf.nn.embedding_lookup(self.word_embedding, self.word_input)              <span class="comment">#batch_size*9*400</span></span><br><span class="line"></span><br><span class="line">        input = tf.concat([word_inut, para_input], axis=<span class="number">1</span>) <span class="comment">#batch_size*10*400</span></span><br><span class="line">        input = tf.layers.flatten(input) <span class="comment">#batch_size*4000</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">"train_parameters"</span>):</span><br><span class="line">            output = tf.layers.dense(input, units=<span class="number">30000</span>, name=<span class="string">"word_output"</span>)</span><br><span class="line">        labels = tf.one_hot(self.word_label, <span class="number">30000</span>)</span><br><span class="line">        train_var = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, <span class="string">"train_parameters"</span>)</span><br><span class="line">        test_var = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, <span class="string">"test_parameters"</span>)</span><br><span class="line">        reg = tf.contrib.layers.apply_regularization(tf.contrib.layers.l2_regularizer(<span class="number">1e-10</span>), tf.trainable_variables())</span><br><span class="line">        self.loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=output))+reg</span><br><span class="line"></span><br><span class="line">        self.train_op = tf.train.AdamOptimizer(learning_rate=<span class="number">0.0001</span>).minimize(self.loss_op, var_list=train_var)</span><br><span class="line">        self.test_op = tf.train.AdamOptimizer(learning_rate=<span class="number">0.0001</span>).minimize(self.loss_op, var_list=test_var)</span><br><span class="line"></span><br><span class="line">        mlp_input = tf.reshape(para_input, [<span class="number">-1</span>, <span class="number">400</span>])</span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">"classification_parameters"</span>):</span><br><span class="line">            h1 = tf.layers.dense(mlp_input, units=<span class="number">50</span>, activation=tf.nn.relu, trainable=<span class="keyword">True</span>, name=<span class="string">"h1"</span>)</span><br><span class="line">            mlp_output = tf.layers.dense(h1, <span class="number">2</span>, trainable=<span class="keyword">True</span>, name=<span class="string">"mlp_output"</span>)</span><br><span class="line">        mlp_labels = tf.one_hot(self.label, <span class="number">2</span>)</span><br><span class="line">        self.mlp_loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=mlp_labels, logits=mlp_output))</span><br><span class="line">        classification_var = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, <span class="string">"classification_parameters"</span>)</span><br><span class="line">        self.mlp_train_op = tf.train.AdamOptimizer(learning_rate=<span class="number">0.02</span>).minimize(self.mlp_loss_op, var_list=classification_var)</span><br><span class="line">        self.predict_op = tf.argmax(mlp_output, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, sess, word_datas, para_datas, word_label, batch_size, is_train=True)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        :param sess: tensorflow的Session，用来运行计算图</span></span><br><span class="line"><span class="string">        :param word_datas: 所有的训练集word词组，大小为m*9，m为样本个数</span></span><br><span class="line"><span class="string">        :param para_datas: 所有的训练集段落id组，大小为m</span></span><br><span class="line"><span class="string">        :param word_label: 所有的词标签，大小为m</span></span><br><span class="line"><span class="string">        :param batch_size: batch_size,是一个标量</span></span><br><span class="line"><span class="string">        :param is_train: 训练的时候和测试的时候都使用这个函数，所以这是一个标志位，标注是训练还是测试</span></span><br><span class="line"><span class="string">        :return: 无</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        index = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> index&lt;len(word_datas):</span><br><span class="line">            word_data_batch = word_datas[index:index+batch_size]</span><br><span class="line">            para_data_batch = para_datas[index:index+batch_size]</span><br><span class="line">            word_label_batch = word_label[index:index+batch_size]</span><br><span class="line">            <span class="keyword">if</span> is_train:</span><br><span class="line">                loss, _ = sess.run([self.loss_op, self.train_op], feed_dict=&#123;self.word_input:word_data_batch, self.para_input:para_data_batch,</span><br><span class="line">                                                                        self.word_label: word_label_batch&#125;)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                loss, _ = sess.run([self.loss_op, self.test_op],</span><br><span class="line">                                   feed_dict=&#123;self.word_input: word_data_batch, self.para_input: para_data_batch,</span><br><span class="line">                                              self.word_label: word_label_batch&#125;)</span><br><span class="line">            <span class="keyword">if</span> index%(batch_size*<span class="number">100</span>)==<span class="number">0</span>:</span><br><span class="line">                print(<span class="string">"Train loss is:"</span>, loss)</span><br><span class="line">                print(index, len(word_datas))</span><br><span class="line">                <span class="keyword">if</span> loss&lt;<span class="number">1</span>:</span><br><span class="line">                    print(word_data_batch)</span><br><span class="line">                    print(word_label_batch)</span><br><span class="line">            index += batch_size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train_mlp</span><span class="params">(self, sess, para_datas, labels, batch_size)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        :param sess: tensorflow的Session</span></span><br><span class="line"><span class="string">        :param para_datas: 所有训练句子id，大小为25000</span></span><br><span class="line"><span class="string">        :param labels: 所有句子的情感标签，大小为25000</span></span><br><span class="line"><span class="string">        :param batch_size: 标量</span></span><br><span class="line"><span class="string">        :return: 无</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        index = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> index &lt; len(para_datas):</span><br><span class="line">            para_data_batch = para_datas[index:index + batch_size]</span><br><span class="line">            label_batch = labels[index:index+batch_size]</span><br><span class="line">            loss, _ = sess.run([self.mlp_loss_op, self.mlp_train_op], feed_dict=&#123;self.para_input: para_data_batch,</span><br><span class="line">                                                                              self.label: label_batch&#125;)</span><br><span class="line">            <span class="keyword">if</span> index%(batch_size*<span class="number">100</span>)==<span class="number">0</span>:</span><br><span class="line">                <span class="comment">#print ("Train loss is:",loss)</span></span><br><span class="line">                <span class="comment">#print (index,len(para_datas))</span></span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line">            index+=batch_size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_mlp</span><span class="params">(self, sess, para_datas, labels, batch_size)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        :param sess: tensorflow的Session</span></span><br><span class="line"><span class="string">        :param para_datas: 所有的测试句子id，大小为25000维的向量</span></span><br><span class="line"><span class="string">        :param labels:  所有的测试句子标签，大小为25000维的向量，用来测试模型结果</span></span><br><span class="line"><span class="string">        :param batch_size:  标量。</span></span><br><span class="line"><span class="string">        :return: 无</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        index=<span class="number">0</span></span><br><span class="line">        result = []</span><br><span class="line">        <span class="keyword">while</span> index &lt; len(para_datas):</span><br><span class="line">            para_data_batch = para_datas[index:index + batch_size]</span><br><span class="line">            pred = sess.run(self.predict_op, feed_dict=&#123;self.para_input: para_data_batch&#125;)</span><br><span class="line">            result += list(pred)</span><br><span class="line">            index += batch_size</span><br><span class="line"></span><br><span class="line">        acc = accuracy_score(y_true=labels, y_pred=result)</span><br><span class="line">        print(<span class="string">"Test acc is:"</span>, acc)</span><br></pre></td></tr></table></figure></p>
<h2 id="训练并预测"><a href="#训练并预测" class="headerlink" title="训练并预测"></a>训练并预测</h2><p>主函数入口，以下代码存放在 <strong><code>main.py</code></strong> 文件中<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> get_all_data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> model</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">'CUDA_VISIBLE_DEVICES'</span>] = str(<span class="number">1</span>) <span class="comment">#设置gpu num，没有gpu随便设置会自动使用cpu</span></span><br><span class="line">data = Dataset()</span><br><span class="line"></span><br><span class="line">session_config = tf.ConfigProto(</span><br><span class="line">                    log_device_placement=<span class="keyword">False</span>,</span><br><span class="line">                    inter_op_parallelism_threads=<span class="number">0</span>,</span><br><span class="line">                    intra_op_parallelism_threads=<span class="number">0</span>,</span><br><span class="line">                    allow_soft_placement=<span class="keyword">True</span>)</span><br><span class="line">session_config.gpu_options.allow_growth = <span class="keyword">True</span> <span class="comment"># 使tensorflow能顾动态申请显存，而不是一下占满</span></span><br><span class="line">m = model(train_first=<span class="keyword">True</span>, train_second=<span class="keyword">False</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session(config=session_config) <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    <span class="comment"># 将这句话注释去掉可以续跑，因为训练句向量训练很多轮，50以上，并且非常慢，所以如果觉得训练的不够多，可以继续训练，而不是从头训练</span></span><br><span class="line">    <span class="comment"># saver.restore(sess, "./model/result.ckpt")</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">50</span>):</span><br><span class="line">        m.train(sess, data.train_word_datas, data.train_para_datas, data.train_new_labels, <span class="number">512</span>)</span><br><span class="line">        saver.save(sess,<span class="string">"./model/result.ckpt"</span>)</span><br><span class="line">tf.reset_default_graph() <span class="comment">#每一次都清空计算图并重新创建。</span></span><br><span class="line">m = model(train_first=<span class="keyword">False</span>, train_second=<span class="keyword">True</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session(config=session_config) <span class="keyword">as</span> sess:</span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    saver.restore(sess,<span class="string">"./model/result.ckpt"</span>)</span><br><span class="line">    train_para = np.reshape(np.array(range(<span class="number">25000</span>)),[<span class="number">25000</span>,<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">        m.train_mlp(sess, train_para[<span class="number">0</span>:<span class="number">20000</span>], data.train_labels[<span class="number">0</span>:<span class="number">20000</span>], <span class="number">32</span>) <span class="comment"># 训练</span></span><br><span class="line">        m.test_mlp(sess, train_para[<span class="number">20000</span>:], data.train_labels[<span class="number">20000</span>:], <span class="number">32</span>) <span class="comment"># 验证</span></span><br><span class="line">    saver.save(sess,<span class="string">"./model/result.ckpt"</span>)</span><br><span class="line">tf.reset_default_graph()</span><br><span class="line">m = model(train_first=<span class="keyword">False</span>, train_second=<span class="keyword">False</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session(config=session_config) <span class="keyword">as</span> sess:</span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    saver.restore(sess,<span class="string">"./model/result.ckpt"</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">50</span>):</span><br><span class="line">        m.train(sess, data.test_word_datas, data.test_para_datas, data.test_new_labels, <span class="number">512</span>, is_train=<span class="keyword">False</span>)</span><br><span class="line">    saver.save(sess,<span class="string">"./model/result.ckpt"</span>)</span><br><span class="line">tf.reset_default_graph()</span><br><span class="line">m = model(train_first=<span class="keyword">False</span>, train_second=<span class="keyword">False</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session(config=session_config) <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    saver.restore(sess, <span class="string">"./model/result.ckpt"</span>)</span><br><span class="line">    test_para = np.reshape(np.array(range(<span class="number">25000</span>)), [<span class="number">25000</span>, <span class="number">1</span>])</span><br><span class="line">    m.test_mlp(sess, test_para, data.test_labels, <span class="number">32</span>)</span><br><span class="line">    saver.save(sess, <span class="string">"./model/result.ckpt"</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>【1】本文复现论文：<a href="https://pan.baidu.com/s/1n9bwGotzg_pRALDfJY-3mg" target="_blank" rel="noopener">Distributed Representations of Sentences and Documents</a><br>提取码：zue5</p>
<p>【2】nltk 数据集工具包：<a href="https://pan.baidu.com/s/1pB3U7ErNAUchouO4Nj-wNA" target="_blank" rel="noopener">nltk_data.zip</a><br>提取码：jpd6 </p>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>坚持原创技术分享，您的支持将鼓励我继续创作！</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.png" alt="Luo Teng 微信支付">
        <p>微信支付</p>
      </div>
    

    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/句向量/" rel="tag"># 句向量</a>
          
            <a href="/tags/sentences-embedding/" rel="tag"># sentences embedding</a>
          
            <a href="/tags/NLP/" rel="tag"># NLP</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/10/08/sentences-embedding-详解/" rel="next" title="sentences embedding 详解">
                <i class="fa fa-chevron-left"></i> sentences embedding 详解
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/10/09/服务器快速下载-kaggle-数据集攻略/" rel="prev" title="服务器快速下载 kaggle 数据集攻略">
                服务器快速下载 kaggle 数据集攻略 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Luo Teng</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">49</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">18</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">67</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/tengzi-will" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.zhihu.com/people/ke-le-teng-zi/activities" target="_blank" title="知乎">
                      
                        <i class="fa fa-fw fa-globe"></i>知乎</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://mumaxu.github.io/" title="mamaxu" target="_blank">mamaxu</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://sunyancn.github.io/" title="sunyan" target="_blank">sunyan</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#下载数据集"><span class="nav-number">1.</span> <span class="nav-text">下载数据集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#程序文件说明"><span class="nav-number">2.</span> <span class="nav-text">程序文件说明</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据预处理"><span class="nav-number">3.</span> <span class="nav-text">数据预处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型构建"><span class="nav-number">4.</span> <span class="nav-text">模型构建</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#训练并预测"><span class="nav-number">5.</span> <span class="nav-text">训练并预测</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考链接"><span class="nav-number">6.</span> <span class="nav-text">参考链接</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Luo Teng</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  


  

  

</body>
</html>
