<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="支持向量机,SVM,">










<meta name="description" content="SVM 概述SVM 诞生于上世纪九十年代，由于它良好的性能，自一诞生便席卷了机器学习领域，并牢牢压制了神经网络领域好多年，据说 LeNet5（一种 CNN 手写数字识别算法，属于神经网络）自 1998 年诞生，在后来的好长一段时间并未能火起来，最主要的原因就是 SVM 这货，因为 SVM 也能达到类似的效果甚至超过 LeNet5， 而且比 LeNet5 计算量小。在不考虑集成学习和特定场景情况下，">
<meta name="keywords" content="支持向量机,SVM">
<meta property="og:type" content="article">
<meta property="og:title" content="支持向量机 SVM 详解">
<meta property="og:url" content="http://yoursite.com/2019/04/14/支持向量机-SVM-详解/index.html">
<meta property="og:site_name" content="LuoTeng&#39;s Blog">
<meta property="og:description" content="SVM 概述SVM 诞生于上世纪九十年代，由于它良好的性能，自一诞生便席卷了机器学习领域，并牢牢压制了神经网络领域好多年，据说 LeNet5（一种 CNN 手写数字识别算法，属于神经网络）自 1998 年诞生，在后来的好长一段时间并未能火起来，最主要的原因就是 SVM 这货，因为 SVM 也能达到类似的效果甚至超过 LeNet5， 而且比 LeNet5 计算量小。在不考虑集成学习和特定场景情况下，">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://i.loli.net/2019/04/14/5cb31eae686bf.png">
<meta property="og:image" content="https://i.loli.net/2019/04/14/5cb31eae6071c.png">
<meta property="og:image" content="https://i.loli.net/2019/04/14/5cb31eae83c60.png">
<meta property="og:image" content="https://i.loli.net/2019/04/14/5cb326af74957.png">
<meta property="og:image" content="https://i.loli.net/2019/04/14/5cb326af80405.png">
<meta property="og:image" content="https://i.loli.net/2019/04/14/5cb33f469343f.png">
<meta property="og:image" content="https://i.loli.net/2019/04/14/5cb33f4698a11.png">
<meta property="og:image" content="https://i.loli.net/2019/04/14/5cb33f471c201.png">
<meta property="og:image" content="http://yoursite.com/支持向量机-SVM-详解/20190415100850127.png">
<meta property="og:image" content="https://i.imgur.com/ACHoQSZ.gif">
<meta property="og:image" content="https://i.loli.net/2019/04/15/5cb40e578b473.png">
<meta property="og:updated_time" content="2019-04-22T08:21:52.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="支持向量机 SVM 详解">
<meta name="twitter:description" content="SVM 概述SVM 诞生于上世纪九十年代，由于它良好的性能，自一诞生便席卷了机器学习领域，并牢牢压制了神经网络领域好多年，据说 LeNet5（一种 CNN 手写数字识别算法，属于神经网络）自 1998 年诞生，在后来的好长一段时间并未能火起来，最主要的原因就是 SVM 这货，因为 SVM 也能达到类似的效果甚至超过 LeNet5， 而且比 LeNet5 计算量小。在不考虑集成学习和特定场景情况下，">
<meta name="twitter:image" content="https://i.loli.net/2019/04/14/5cb31eae686bf.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/04/14/支持向量机-SVM-详解/">





  <title>支持向量机 SVM 详解 | LuoTeng's Blog</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">LuoTeng's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">每一个不曾起舞的日子都是对生命的辜负</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/14/支持向量机-SVM-详解/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Luo Teng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LuoTeng's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">支持向量机 SVM 详解</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-14T17:43:17+08:00">
                2019-04-14
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/算法/" itemprop="url" rel="index">
                    <span itemprop="name">算法</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="SVM-概述"><a href="#SVM-概述" class="headerlink" title="SVM 概述"></a>SVM 概述</h2><p><strong>SVM</strong> 诞生于上世纪九十年代，由于它良好的性能，自一诞生便席卷了机器学习领域，并牢牢压制了神经网络领域好多年，据说 <strong>LeNet5</strong>（一种 <strong>CNN</strong> 手写数字识别算法，属于神经网络）自 1998 年诞生，在后来的好长一段时间并未能火起来，最主要的原因就是 <strong>SVM</strong> 这货，因为 <strong>SVM</strong> 也能达到类似的效果甚至超过 <strong>LeNet5</strong>， 而且比 <strong>LeNet5</strong> 计算量小。在不考虑集成学习和特定场景情况下，在分类算法中 <strong>SVM</strong> 毫无疑问是性能最好的分类器。下面就 <strong>SVM</strong> 的算法原理做一下总结和探讨。</p>
<p><strong>SVM</strong> 的基本形式是一个有监督的线性二分类模型，它是间隔最大化的分类器。主要包括以下几种形式：</p>
<ul>
<li>当训练数据线性可分时，支持向量机通过硬间隔最大化学习分类器，称为硬间隔支持向量机；<br><img src="https://i.loli.net/2019/04/14/5cb31eae686bf.png" alt="01_SVM_HardMargin"></li>
<li>当训练数据近似线性可分时，支持向量机通过软间隔最大化学习分类器，称为软间隔支持向量机；<br><img src="https://i.loli.net/2019/04/14/5cb31eae6071c.png" alt="02_SVM_SoftMargin"></li>
<li>当训练数据线性不可分时，支持向量机通过核技巧和软间隔最大化学习分类器，称为非线性支持向量机；<br><img src="https://i.loli.net/2019/04/14/5cb31eae83c60.png" alt="03_SVM_Kernel"></li>
</ul>
<p>此外，<strong>SVM</strong> 既支持二元分类也支持多元分类，既支持分类问题也支持回归问题。</p>
<h2 id="线性可分支持向量机"><a href="#线性可分支持向量机" class="headerlink" title="线性可分支持向量机"></a>线性可分支持向量机</h2><h3 id="函数间隔与几何间隔"><a href="#函数间隔与几何间隔" class="headerlink" title="函数间隔与几何间隔"></a>函数间隔与几何间隔</h3><h3 id="凸优化问题"><a href="#凸优化问题" class="headerlink" title="凸优化问题"></a>凸优化问题</h3><ol>
<li>无约束优化问题（费马定理）：<br>$$\min f(x)$$</li>
<li>带等式约束的优化问题（拉格朗日乘子法）：<br>$$\begin{array}{c}{\min f(x)} \\ {\text { s.t. } h_{i}(x)=0, \quad i=1,2, \cdots n} \\ \mathcal{L}(x, \lambda)=f(x)+\sum_{i=1}^{n} \lambda_{i} h_{i}(x) \end{array}$$</li>
<li>带不等式约束的优化问题（KKT条件）：<br>$$\begin{array}{c}{\min f(x)} \\ {\text {s.t.} h_{i}(x)=0, \quad i=1,2, \cdots, n} \\ {g_{i}(x) \leq 0, \quad i=1,2, \cdots, k} \\ \mathcal{L}(x, \lambda, v)=f(x)+\sum_{i=1}^{k} \lambda_{i} g_{i}(x)+\sum_{i=1}^{n} v_{i} h_{i}(x) \end{array}$$</li>
</ol>
<h3 id="对偶问题"><a href="#对偶问题" class="headerlink" title="对偶问题"></a>对偶问题</h3><h3 id="序列最小化-SMO-算法"><a href="#序列最小化-SMO-算法" class="headerlink" title="序列最小化 SMO 算法"></a>序列最小化 SMO 算法</h3><h2 id="软间隔支持向量机"><a href="#软间隔支持向量机" class="headerlink" title="软间隔支持向量机"></a>软间隔支持向量机</h2><h3 id="线性分类-SVM-面临的问题"><a href="#线性分类-SVM-面临的问题" class="headerlink" title="线性分类 SVM 面临的问题"></a>线性分类 SVM 面临的问题</h3><p>在节中，我们对线性可分 <strong>SVM</strong> 的算法的原理和流程进行了总结，如下图所示，为线性可分的数据集，我们可以采用线性可分的支持向量机，也称为硬间隔支持向量机。</p>
<p><img src="https://i.loli.net/2019/04/14/5cb326af74957.png" alt="06_Hard"></p>
<p>当数据集中参杂了一些噪声，如下图所示，由于参杂了一个红色的噪声点，导致模型学习到的决策边界由下图中的粗虚线移动到了粗实线。</p>
<p><img src="https://i.loli.net/2019/04/14/5cb326af80405.png" alt="07_noise"></p>
<p><strong>上图是粗实线作为决策边界更合理，还是粗虚线作为决策边界更合理？</strong>很显然是粗虚线更合理，因为粗虚线忽略了噪音的影响，其 <strong>margin</strong> 更大，在测试集上的效果要优于粗实线。</p>
<p><strong>如何解决这些问题呢？</strong> <strong>SVM</strong> 引入了<strong>软间隔最大化</strong>的方法来解决。</p>
<h3 id="硬间隔-SVM-回顾"><a href="#硬间隔-SVM-回顾" class="headerlink" title="硬间隔 SVM 回顾"></a>硬间隔 SVM 回顾</h3><p>回顾下最大硬间隔的 <strong>SVM</strong>：</p>
<p>$$\min \frac{1}{2}|w|_ {2}^{2} \quad \text { s.t } y_{i}\left(w^{T} x_{i}+b\right) \geq 1(i=1,2, \ldots m)$$</p>
<p>硬间隔支持向量机，如下图所示：</p>
<p><img src="https://i.loli.net/2019/04/14/5cb33f469343f.png" alt="08_Hard"></p>
<p>所有的样本点均到决策超平面的距离均不小于 1，硬间隔 <strong>SVM</strong> 的下限为：</p>
<p>$$y_{i}\left(w^{T} x_{i}+b\right) \geq 1$$</p>
<p>$H_1$ 和 $H_2$ 像两堵墙一样将两类样本分隔开。</p>
<h3 id="引入松弛变量-xi"><a href="#引入松弛变量-xi" class="headerlink" title="引入松弛变量 $\xi$"></a>引入松弛变量 $\xi$</h3><p>当数据中增加噪声点或误分类以后，比如在 $H_1$ 和 $H_2$ 之间，<strong>SVM</strong> 引入了一个神奇的变量 $\xi_i \ge 0$ ，这个变量被称为<strong>松弛变量</strong>，其几何含义由下图所示：</p>
<p><img src="https://i.loli.net/2019/04/14/5cb33f4698a11.png" alt="09_XI"></p>
<p>简单明了，以红点样本为例，$\xi$ 表示到 $H_1$ 的距离：</p>
<p>当样本点在 $H_1$ 右边时，包括支持向量和支持向量以外的样本点时 $\xi_i = 0$ ，即我们可以按照硬间隔来处理。</p>
<p>对于 $H_1$ 左侧的样本点，样本的 $\xi &gt; 0$ ，包括两种情况，一种是正确分类，但是在 <strong>margin</strong> 范围内的样本点 (也就是超平面附近的点)，此时 $0&lt; \xi &lt; 1$；一类是误分类的点，此时 $\xi &gt;1$</p>
<h3 id="1-xi-的几何含义"><a href="#1-xi-的几何含义" class="headerlink" title="$1-\xi$ 的几何含义"></a>$1-\xi$ 的几何含义</h3><p>对于噪声点和误分类的样本点来说，$1-\xi$ 表示该样本点到决策超平面之间的距离，而且是有向距离。具体而言，噪声点到超平面的距离为 $0&lt;1-\xi&lt;1$，误分类点到超平面的距离为 $1-\xi&lt;0$ 。</p>
<p>加入松弛变量 $\xi$ 之后，我们的 $H_1$ 和 $H_2$ 像弹簧一样，针对不同的样本点做不同的处理，变 “软”了。写成数学公式为：<br>$$y_{i}\left(w^{T} x_{i}+b\right) \geq 1-\xi_{i}, \quad \xi_{i} \geq 0$$<br>上式即为软间隔支持向量机的约束条件。</p>
<h3 id="优化下界"><a href="#优化下界" class="headerlink" title="优化下界"></a>优化下界</h3><p>我们知道，只要我们拉伸弹簧，我们就会消耗能量，付出代价。同理松弛变量的添加也是有成本的，每一个松弛变量 $\xi_i$ 都支付了一个代价 $\xi_i$， 现在代价函数变成了：</p>
<p>$$\min \frac{1}{2}|w|_ {2}^{2} \Rightarrow \min \frac{1}{2}|w|_ {2}^{2}+C \sum_{i=1}^{m} \xi_{i}$$</p>
<p>这个公式的原理还是不够明了，让我们还原一下，看看这个到底是什么个意思。</p>
<p>$$\min \frac{1}{2}|w|_ {2}^{2} \Rightarrow \max \frac{2}{|w|_ {2}^{2}}$$</p>
<p>$$\min \frac{C}{m} \sum_{i=1}^{m} \xi_{i} \Rightarrow \max \frac{C}{m} \sum_{i=1}^{m}\left(1-\xi_{i}\right)$$</p>
<p>显然对于支持向量和支持向量以外的点， $max\; \frac{2}{||w||_ 2^2}$ ，相当于最大化 <strong>margin</strong> 。</p>
<p>$max\;\frac C m\sum\limits_{i=1}^{m}(1-\xi_i)$ 对于 <strong>margin</strong> 内的噪声点，最大化噪声点和决策边界之间的距离$1-\xi_i$；对于误分类的点，其到决策边界之间的距离为 $-(1-\xi_i)$，那么 $max\;\;C\sum\limits_{i=1}^{m}(1-\xi_i)\Rightarrow min\;\;|C\sum\limits_{i=1}^{m}(1-\xi_i)|$ ，也就是最小化误分类点到决策边界之间的距离，翻译成汉语就是让其尽量不要错得那么离谱。</p>
<h3 id="软间隔-SVM-的优化目标"><a href="#软间隔-SVM-的优化目标" class="headerlink" title="软间隔 SVM 的优化目标"></a>软间隔 SVM 的优化目标</h3><p>综合起来，我们就得到了最大软间隔 <strong>SVM</strong> 的优化目标：</p>
<p>$$ \begin{array}{c}{\min \frac{1}{2}|w|_ {2}^{2}+\frac{C}{m} \sum_{i=1}^{m} \xi_{i}} \\ {\text {s.t. } y_{i}\left(w^{T} x_{i}+b\right) \geq 1-\xi_{i} \quad(i=1,2, \ldots m)} \\ {\xi_{i} \geq 0 \quad(i=1,2, \ldots m)}\end{array} $$</p>
<p>最小化 $\frac{1}{2}||w||_ 2^2$ 意味着让支持向量距离超平面的距离尽可能大，最小化 $\sum\limits_{i=1}^{m}\xi_i $ 意味着保证 <strong>margin</strong> 内的点尽可能远离超平面，对误分类的点不要偏离的太远。$C$ 是协调两者关系的系数，需要调参来选择。</p>
<p>下面是取不同的 $C$ 值的分类器对比情况，这两种分类器的性能相差不大，都比较差。$C$ 越小，<strong>margin</strong> 越大，$C$ 越大，<strong>margin</strong> 越小。$C$ 越大，$\sum\limits_{i=1}^{m}\xi_i$  作用越大，模型会更多得关注噪声点和误分类点，即决策边界周围的点，$C$ 越小，模型会更多关注距离决策边界更远的点，当 $C=0$ 时，软间隔变成了硬间隔。 $C$ 的取值可以采用交叉验证的方式求得。</p>
<p><img src="https://i.loli.net/2019/04/14/5cb33f471c201.png" alt="10_C"></p>
<h2 id="SVM-损失函数"><a href="#SVM-损失函数" class="headerlink" title="SVM 损失函数"></a>SVM 损失函数</h2><p>总结一下，关于线性支持向量机我们学了三种代价函数：</p>
<ul>
<li>合页损失函数 (hinge loss function)：<br>$$\min \frac{1}{m} \sum_{i=1}^{m} \max {0,1-y_{i}(w^{T} x_{i}+b)}+\frac{\lambda}{2}|w|_ {2}^{2}$$</li>
<li>硬间隔损失函数：<br>$$\min \frac{1}{2}|w|_ {2}^{2} \quad \text { s.t } y_{i}\left(w^{T} x_{i}+b\right) \geq 1(i=1,2, \ldots m)$$</li>
<li>软间隔损失函数：<br>$$\begin{array}{c}{\min \frac{1}{2}|w|_ {2}^{2}+\frac{C}{m} \sum_{i=1}^{m} \xi_{i}} \\\\ {\text {s.t. } y_{i}\left(w^{T} x_{i}+b\right) \geq 1-\xi_{i} \quad(i=1,2, \ldots m)} \\\\ {\xi_{i} \geq 0(i=1,2, \ldots m)}\end{array}$$</li>
</ul>
<p>其实归根到底都是合页损失函数。</p>
<p><strong>推导以后补充</strong></p>
<h2 id="非线性支持向量机与核函数"><a href="#非线性支持向量机与核函数" class="headerlink" title="非线性支持向量机与核函数"></a>非线性支持向量机与核函数</h2><p>以上介绍的都是 <strong>SVM</strong> 作为线性分类器的作用，那对于非线性问题，<strong>SVM</strong> 该怎样做呢？ 　　　</p>
<p>对于非线性问题，我们采取的做法是将进行一个非线性变换映射到特征空间中，将原空间非线性问题转变为特征空间的线性问题，然后再用线性分类器 <strong>SVM</strong> 求解。什么意思呢？我们举例说明：</p>
<p><img src="/支持向量机-SVM-详解/20190415100850127.png" alt="11_1"></p>
<p>图中的两类数据，分别分布为两个圆圈的形状，因为这样的数据本身就是线性不可分的，线性分类器是没法处理。<strong>那我们该如何处理呢？</strong></p>
<p>对于上图的数据，我们可以表示为：</p>
<p>$$a_{1} X_{1}^{2}+a_{2}\left(X_{2}-c\right)^{2}+a_{3}=0$$</p>
<p>其中 $X_1$ 和 $X_2$ 是两个坐标系。</p>
<p>我们令 $Z_1=X^2_1, Z_2=X^2_2, Z_3=X_2$ （其中 $Z_1, Z_2, Z_3$ 为三维空间的三个坐标）将其映射到三维空间中进行求解，如下图：</p>
<p><img src="https://i.imgur.com/ACHoQSZ.gif" alt="11_2"></p>
<p>可以找到一个平面，将红色的样本和蓝色样本区分开。</p>
<p>下面展示了另一种特征映射和线性分类相结合的方式：<br><img src="https://i.loli.net/2019/04/15/5cb40e578b473.png" alt="11_3"></p>
<p>也就是说对于在低维线性不可分的数据，在映射到了高维以后，就变成线性可分的了。这个思想我们同样可以运用到 <strong>SVM</strong> 的线性不可分数据上。也就是说，对于 <strong>SVM</strong> 线性不可分的低维特征数据，我们可以将其映射到高维，就可以运用线性可分 <strong>SVM</strong> 的进行求解了。</p>
<h3 id="核函数的引入"><a href="#核函数的引入" class="headerlink" title="核函数的引入"></a>核函数的引入</h3><h4 id="核函数的定义"><a href="#核函数的定义" class="headerlink" title="核函数的定义"></a>核函数的定义</h4><p>假设 $\phi$ 是一个从低维的输入空间 $\chi$（欧式空间的子集或者离散集合）到高维的希尔伯特空间的 $H$ 映射。对于所有的 $x, z \in \chi$，都有 $K(x, z)$ 满足：</p>
<p>$$K(x, z)=\phi(x) \cdot \phi(z)$$</p>
<p>那么我们就称 $K(x, z)$ 为核函数，$\phi(x)$ 为映射函数 。式中 $\phi(x) \cdot \phi(z)$ 为 $\phi(x)$ 和 $\phi(z)$ 的内积。</p>
<h4 id="核技巧在支持向量机中的应用"><a href="#核技巧在支持向量机中的应用" class="headerlink" title="核技巧在支持向量机中的应用"></a>核技巧在支持向量机中的应用</h4><p>回顾线性可分 <strong>SVM</strong> 对偶问题的优化目标函数：</p>
<p>$$\underbrace{\min }_ {\alpha} \frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_{i} \alpha_{j} y_{i} y_{j}\left(x_{i} \cdot x_{j}\right)-\sum_{i=1}^{m} \alpha_{i} \\\\ {\quad \text {s.t.} \sum_{i=1}^{m} \alpha_{i} y_{i}=0} \\\\ {0 \leq \alpha_{i} \leq C ,i=1,2, \ldots m}$$</p>
<p>我们定义一个低维特征空间到高维特征空间的映射 $\phi$，将所有输入空间映射到一个更高维度的特征空间，让数据线性可分，我们就可以利用 <strong>SVM</strong> 的优化目标函数求出分类决策边界了。也就是说现在的 <strong>SVM</strong> 的优化目标函数变成：</p>
<p>$$\underbrace{\min }_ {\alpha} \frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_{i} \alpha_{j} y_{i} y_{j}[\phi(x_{i}) \cdot \phi(x_{j})]-\sum_{i=1}^{m} \alpha_{i}$$<br>上式 $\phi(x_{i}) \cdot \phi(x_{j})$ 替换为核函数：<br>$$\underbrace{\min }_ {\alpha} \frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_{i} \alpha_{j} y_{i} y_{j}K(x_i, x_j)-\sum_{i=1}^{m} \alpha_{i}$$</p>
<p>同样，分类决策函数中的内积也可以用核函数代替，得到的超平面即为：</p>
<p>$$f(x)={sign}\left(\sum_{i=1}^{m} \alpha_{i}^{\ast} y_{i}\left(\phi\left(x_{i}\right) \cdot \phi(x)\right)+b^{\ast}\right) = {sign}\left(\sum_{i=1}^{m} \alpha_{i}^{\ast} y_{i}K(x_i, x_j)+b^{\ast}\right) $$</p>
<h3 id="核函数介绍"><a href="#核函数介绍" class="headerlink" title="核函数介绍"></a>核函数介绍</h3><p>从上面的分析发现，因此我们只需要定义核函数 $K(x,z)$，而不用显示的定义映射函数  $\phi$ ，即可求出 $\phi(x_i) \cdot \phi(x_j)$， 这样就省去了寻找映射函数的麻烦（映射函数有无数个）。但是却带来了另一个问题：我们怎样定义核函数 $K(x,z)$ 呢？</p>
<p>其实已经有人帮我们找到了很多的核函数，而且常用的核函数也仅仅只有那么几个。下面我们简要介绍 <strong>sklearn</strong> 中默认可选的几个核函数。</p>
<h4 id="线性核函数"><a href="#线性核函数" class="headerlink" title="线性核函数"></a>线性核函数</h4><p>线性核函数（<strong>Linear Kernel</strong>）其实就是线性可分 <strong>SVM</strong>，表达式为：</p>
<p>$$K(x, z)=x \cdot z$$</p>
<p>也就是说，线性 <strong>SVM</strong> 是非线性 <strong>SVM</strong> 的一个特殊的情况，即线性 <strong>SVM</strong> 是使用线性核函数的 <strong>SVM</strong>。</p>
<h4 id="多项式核函数"><a href="#多项式核函数" class="headerlink" title="多项式核函数"></a>多项式核函数</h4><h4 id="高斯核函数"><a href="#高斯核函数" class="headerlink" title="高斯核函数"></a>高斯核函数</h4><h4 id="拉普拉斯核函数"><a href="#拉普拉斯核函数" class="headerlink" title="拉普拉斯核函数"></a>拉普拉斯核函数</h4><h4 id="Sigmoid核函数"><a href="#Sigmoid核函数" class="headerlink" title="Sigmoid核函数"></a>Sigmoid核函数</h4><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://zhuanlan.zhihu.com/p/36332083" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/36332083</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/36379394" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/36379394</a></p>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>坚持原创技术分享，您的支持将鼓励我继续创作！</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.png" alt="Luo Teng 微信支付">
        <p>微信支付</p>
      </div>
    

    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/支持向量机/" rel="tag"># 支持向量机</a>
          
            <a href="/tags/SVM/" rel="tag"># SVM</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/04/11/深度学习-速查手册/" rel="next" title="深度学习 速查手册">
                <i class="fa fa-chevron-left"></i> 深度学习 速查手册
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/04/22/支持向量机-SVM-算法实战/" rel="prev" title="支持向量机 SVM 算法实战">
                支持向量机 SVM 算法实战 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Luo Teng</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">39</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">19</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">59</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/tengzi-will" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.zhihu.com/people/ke-le-teng-zi/activities" target="_blank" title="知乎">
                      
                        <i class="fa fa-fw fa-globe"></i>知乎</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://mumaxu.github.io/" title="mamaxu" target="_blank">mamaxu</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://sunyancn.github.io/" title="sunyan" target="_blank">sunyan</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#SVM-概述"><span class="nav-number">1.</span> <span class="nav-text">SVM 概述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#线性可分支持向量机"><span class="nav-number">2.</span> <span class="nav-text">线性可分支持向量机</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#函数间隔与几何间隔"><span class="nav-number">2.1.</span> <span class="nav-text">函数间隔与几何间隔</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#凸优化问题"><span class="nav-number">2.2.</span> <span class="nav-text">凸优化问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#对偶问题"><span class="nav-number">2.3.</span> <span class="nav-text">对偶问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#序列最小化-SMO-算法"><span class="nav-number">2.4.</span> <span class="nav-text">序列最小化 SMO 算法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#软间隔支持向量机"><span class="nav-number">3.</span> <span class="nav-text">软间隔支持向量机</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#线性分类-SVM-面临的问题"><span class="nav-number">3.1.</span> <span class="nav-text">线性分类 SVM 面临的问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#硬间隔-SVM-回顾"><span class="nav-number">3.2.</span> <span class="nav-text">硬间隔 SVM 回顾</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#引入松弛变量-xi"><span class="nav-number">3.3.</span> <span class="nav-text">引入松弛变量 $\xi$</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-xi-的几何含义"><span class="nav-number">3.4.</span> <span class="nav-text">$1-\xi$ 的几何含义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#优化下界"><span class="nav-number">3.5.</span> <span class="nav-text">优化下界</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#软间隔-SVM-的优化目标"><span class="nav-number">3.6.</span> <span class="nav-text">软间隔 SVM 的优化目标</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SVM-损失函数"><span class="nav-number">4.</span> <span class="nav-text">SVM 损失函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#非线性支持向量机与核函数"><span class="nav-number">5.</span> <span class="nav-text">非线性支持向量机与核函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#核函数的引入"><span class="nav-number">5.1.</span> <span class="nav-text">核函数的引入</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#核函数的定义"><span class="nav-number">5.1.1.</span> <span class="nav-text">核函数的定义</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#核技巧在支持向量机中的应用"><span class="nav-number">5.1.2.</span> <span class="nav-text">核技巧在支持向量机中的应用</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#核函数介绍"><span class="nav-number">5.2.</span> <span class="nav-text">核函数介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#线性核函数"><span class="nav-number">5.2.1.</span> <span class="nav-text">线性核函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#多项式核函数"><span class="nav-number">5.2.2.</span> <span class="nav-text">多项式核函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#高斯核函数"><span class="nav-number">5.2.3.</span> <span class="nav-text">高斯核函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#拉普拉斯核函数"><span class="nav-number">5.2.4.</span> <span class="nav-text">拉普拉斯核函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Sigmoid核函数"><span class="nav-number">5.2.5.</span> <span class="nav-text">Sigmoid核函数</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考链接"><span class="nav-number">6.</span> <span class="nav-text">参考链接</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Luo Teng</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
